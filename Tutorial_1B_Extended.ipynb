{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Extended RNA-Seq Analysis Training Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity and time, The short tutorial workflow uses only partial run data from the Cushman et al., project.\n",
    "\n",
    "The tutorial repeats the short tutorial, but with extended steps.\n",
    "\n",
    "This tutorial demonstrates how to run an RNA-Seq workflow using a prokaryotic data set. Steps in the workflow include read trimming, read QC, read mapping, and counting mapped reads per gene to quantitate gene expression. Extended steps include using SRA tools to download the full dataset, joining gene count results, and formatting those results for use in R for further downstream analysis.\n",
    "\n",
    "For those seeking practice, we encourage you to create your own notebook and attempt to repeat through the full work flow yourself from scratch, using this extended tutorial as a reference as needed.\n",
    "\n",
    "Note: As this tutorial deals with non-truncated 'big data', the analysis in this workflow may take around 1 and a half hours to fully run the code. \n",
    "\n",
    "![RNA-Seq workflow](images/rnaseq-workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: Install Mambaforge and then install snakemake using bioconda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First install Mambaforge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 88.6M  100 88.6M    0     0  26.5M      0  0:00:03  0:00:03 --:--:-- 32.6M\n",
      "PREFIX=/home/jupyter/mambaforge\n",
      "Unpacking payload ...\n",
      "Extracting \"dropbox-11.31.0-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/dropbox-11.31.0-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libcups-2.3.3-hf5a7f15_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libcups-2.3.3-hf5a7f15_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"humanfriendly-10.0-py37h89c1867_2.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/humanfriendly-10.0-py37h89c1867_2/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"font-ttf-dejavu-sans-mono-2.37-hab24e00_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/font-ttf-dejavu-sans-mono-2.37-hab24e00_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"zstd-1.5.2-ha95c52a_0.tar.bz2\"\n",
      "Extracting \"libgcc-ng-11.2.0-h1d223b6_14.tar.bz2\"\n",
      "Extracting \"attmap-0.13.2-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/attmap-0.13.2-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"rich-12.4.4-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/rich-12.4.4-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"xorg-renderproto-0.11.1-h7f98852_1002.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/xorg-renderproto-0.11.1-h7f98852_1002/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libtiff-4.3.0-h0fcbabc_4.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libtiff-4.3.0-h0fcbabc_4/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"yaml-0.2.5-h7f98852_2.tar.bz2\"\n",
      "Extracting \"fonts-conda-ecosystem-1-0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/fonts-conda-ecosystem-1-0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"reproc-14.2.3-h7f98852_0.tar.bz2\"\n",
      "Extracting \"mamba-0.22.1-py39hfa8f2c8_0.tar.bz2\"\n",
      "Extracting \"python-3.9.10-h85951f9_2_cpython.tar.bz2\"\n",
      "Extracting \"datrie-0.8.2-py37h5e8e339_3.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/datrie-0.8.2-py37h5e8e339_3/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"pillow-9.1.1-py310he619898_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/pillow-9.1.1-py310he619898_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libstdcxx-ng-11.2.0-he4da1e4_14.tar.bz2\"\n",
      "Extracting \"conda-4.12.0-py39hf3d152e_0.tar.bz2\"\n",
      "Extracting \"pixman-0.40.0-h36c2ea0_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/pixman-0.40.0-h36c2ea0_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"fonts-conda-forge-1-0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/fonts-conda-forge-1-0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libcurl-7.83.1-h7bff187_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libcurl-7.83.1-h7bff187_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libbrotlicommon-1.0.9-h166bdaf_7.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libbrotlicommon-1.0.9-h166bdaf_7/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"cairo-1.16.0-h6cf1ce9_1008.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/cairo-1.16.0-h6cf1ce9_1008/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-constant-1.33-pl5321hd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-constant-1.33-pl5321hd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"spectra-0.0.11-py_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/spectra-0.0.11-py_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"giflib-5.2.1-h36c2ea0_2.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/giflib-5.2.1-h36c2ea0_2/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"python-irodsclient-1.1.3-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/python-irodsclient-1.1.3-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"aioeasywebdav-2.4.0-py37h89c1867_1001.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/aioeasywebdav-2.4.0-py37h89c1867_1001/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"matplotlib-base-3.5.2-py310h5701ce4_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/matplotlib-base-3.5.2-py310h5701ce4_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"brotlipy-0.7.0-py310h5764c6d_1004.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/brotlipy-0.7.0-py310h5764c6d_1004/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"c-ares-1.18.1-h7f98852_0.tar.bz2\"\n",
      "Extracting \"openssl-3.0.3-h166bdaf_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/openssl-3.0.3-h166bdaf_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"markdown-3.3.7-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/markdown-3.3.7-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-business-isbn-3.007-pl5321hdfd78af_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-business-isbn-3.007-pl5321hdfd78af_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"click-8.1.3-py310hff52083_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/click-8.1.3-py310hff52083_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libmambapy-0.22.1-py39h3216e65_0.tar.bz2\"\n",
      "Extracting \"xorg-libxrender-0.9.10-h7f98852_1003.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/xorg-libxrender-0.9.10-h7f98852_1003/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"alsa-lib-1.2.6.1-h7f98852_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/alsa-lib-1.2.6.1-h7f98852_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"python-dateutil-2.8.2-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/python-dateutil-2.8.2-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"xorg-libice-1.0.10-h7f98852_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/xorg-libice-1.0.10-h7f98852_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"coin-or-cgl-0.60.6-he2f9439_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/coin-or-cgl-0.60.6-he2f9439_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"coin-or-clp-1.17.6-h256e9bb_3.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/coin-or-clp-1.17.6-h256e9bb_3/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libzlib-1.2.11-h36c2ea0_1013.tar.bz2\"\n",
      "Extracting \"_openmp_mutex-4.5-1_gnu.tar.bz2\"\n",
      "Extracting \"xorg-libxfixes-5.0.3-h7f98852_1004.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/xorg-libxfixes-5.0.3-h7f98852_1004/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libgomp-11.2.0-h1d223b6_14.tar.bz2\"\n",
      "Extracting \"filechunkio-1.8-py_2.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/filechunkio-1.8-py_2/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"pyparsing-3.0.9-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/pyparsing-3.0.9-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"ruamel_yaml-0.15.80-py39h3811e60_1006.tar.bz2\"\n",
      "Extracting \"iniconfig-1.1.1-pyh9f0ad1d_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/iniconfig-1.1.1-pyh9f0ad1d_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"snakemake-minimal-7.8.0-pyhdfd78af_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/snakemake-minimal-7.8.0-pyhdfd78af_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"xorg-libxi-1.7.10-h7f98852_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/xorg-libxi-1.7.10-h7f98852_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"pyyaml-6.0-py310h5764c6d_4.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/pyyaml-6.0-py310h5764c6d_4/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"docutils-0.18.1-py37h89c1867_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/docutils-0.18.1-py37h89c1867_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"tqdm-4.63.0-pyhd8ed1ab_0.tar.bz2\"\n",
      "Extracting \"font-ttf-ubuntu-0.83-hab24e00_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/font-ttf-ubuntu-0.83-hab24e00_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libbrotlienc-1.0.9-h166bdaf_7.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libbrotlienc-1.0.9-h166bdaf_7/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"liblapack-3.9.0-14_linux64_openblas.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/liblapack-3.9.0-14_linux64_openblas/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"coloredlogs-15.0.1-pyhd8ed1ab_3.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/coloredlogs-15.0.1-pyhd8ed1ab_3/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"tk-8.6.12-h27826a3_0.tar.bz2\"\n",
      "Extracting \"perl-file-chdir-0.1010-pl5321hdfd78af_3.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-file-chdir-0.1010-pl5321hdfd78af_3/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"kiwisolver-1.4.2-py310hbf28c38_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/kiwisolver-1.4.2-py310hbf28c38_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"future-0.18.2-py37h89c1867_5.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/future-0.18.2-py37h89c1867_5/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libwebp-1.2.2-h3452ae3_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libwebp-1.2.2-h3452ae3_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-xml-sax-1.02-pl5321hdfd78af_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-xml-sax-1.02-pl5321hdfd78af_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libssh2-1.10.0-ha56f1ee_2.tar.bz2\"\n",
      "Extracting \"perl-test2-suite-0.000145-pl5321hdfd78af_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-test2-suite-0.000145-pl5321hdfd78af_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"tbb-2021.5.0-h924138e_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/tbb-2021.5.0-h924138e_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"unicodedata2-14.0.0-py310h5764c6d_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/unicodedata2-14.0.0-py310h5764c6d_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"xorg-xextproto-7.3.0-h7f98852_1002.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/xorg-xextproto-7.3.0-h7f98852_1002/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"pygments-2.12.0-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/pygments-2.12.0-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-scope-guard-0.21-pl5321hdfd78af_3.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-scope-guard-0.21-pl5321hdfd78af_3/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"xorg-recordproto-1.14.2-h7f98852_1002.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/xorg-recordproto-1.14.2-h7f98852_1002/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"pysftp-0.2.9-py_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/pysftp-0.2.9-py_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"coin-or-osi-0.108.7-h3b589db_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/coin-or-osi-0.108.7-h3b589db_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"python_abi-3.10-2_cp310.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/python_abi-3.10-2_cp310/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"idna-3.3-pyhd8ed1ab_0.tar.bz2\"\n",
      "Extracting \"fonttools-4.33.3-py310h5764c6d_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/fonttools-4.33.3-py310h5764c6d_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libnghttp2-1.47.0-h727a467_0.tar.bz2\"\n",
      "Extracting \"pigz-2.3.4-hed695b0_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/pigz-2.3.4-hed695b0_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"reproc-cpp-14.2.3-h9c3ff4c_0.tar.bz2\"\n",
      "Extracting \"simplejson-3.17.6-py310h5764c6d_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/simplejson-3.17.6-py310h5764c6d_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"icu-70.1-h27087fc_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/icu-70.1-h27087fc_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libgfortran5-12.1.0-hdcd56e2_16.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libgfortran5-12.1.0-hdcd56e2_16/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"cryptography-37.0.1-py310h9ce1e76_0.conda\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/cryptography-37.0.1-py310h9ce1e76_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"py-1.11.0-pyh6c4a22f_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/py-1.11.0-pyh6c4a22f_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"salmon-1.8.0-h7e5ed60_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/salmon-1.8.0-h7e5ed60_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"gffread-0.12.7-hd03093a_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/gffread-0.12.7-hd03093a_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"lz4-c-1.9.3-h9c3ff4c_1.tar.bz2\"\n",
      "Extracting \"commonmark-0.9.1-py_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/commonmark-0.9.1-py_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"cffi-1.15.0-py39h4bc2ebd_0.tar.bz2\"\n",
      "Extracting \"ubiquerg-0.6.1-pyh9f0ad1d_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/ubiquerg-0.6.1-pyh9f0ad1d_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"cryptography-36.0.2-py39hd97740a_0.tar.bz2\"\n",
      "Extracting \"slacker-0.14.0-py_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/slacker-0.14.0-py_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"ratelimiter-1.2.0-py_1002.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/ratelimiter-1.2.0-py_1002/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"pysocks-1.7.1-py39hf3d152e_4.tar.bz2\"\n",
      "Extracting \"certifi-2022.5.18.1-py310hff52083_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/certifi-2022.5.18.1-py310hff52083_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"pthread-stubs-0.4-h36c2ea0_1001.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/pthread-stubs-0.4-h36c2ea0_1001/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"cycler-0.11.0-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/cycler-0.11.0-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"stone-3.3.1-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/stone-3.3.1-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"gettext-0.19.8.1-h73d1719_1008.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/gettext-0.19.8.1-h73d1719_1008/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"salmon-1.7.0-h84f40af_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/salmon-1.7.0-h84f40af_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-term-table-0.016-pl5321hdfd78af_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-term-table-0.016-pl5321hdfd78af_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"lcms2-2.12-hddcbb42_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/lcms2-2.12-hddcbb42_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-ffi-checklib-0.28-pl5321hdfd78af_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-ffi-checklib-0.28-pl5321hdfd78af_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"bzip2-1.0.8-h7f98852_4.tar.bz2\"\n",
      "Extracting \"trimmomatic-0.39-hdfd78af_2.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/trimmomatic-0.39-hdfd78af_2/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"pip-22.1.1-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/pip-22.1.1-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"stopit-1.1.2-py_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/stopit-1.1.2-py_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"connection_pool-0.0.3-pyhd3deb0d_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/connection_pool-0.0.3-pyhd3deb0d_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"packaging-21.3-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/packaging-21.3-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"pycparser-2.21-pyhd8ed1ab_0.tar.bz2\"\n",
      "Extracting \"perl-uri-5.10-pl5321hdfd78af_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-uri-5.10-pl5321hdfd78af_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libwebp-base-1.2.2-h7f98852_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libwebp-base-1.2.2-h7f98852_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"liblapacke-3.9.0-14_linux64_openblas.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/liblapacke-3.9.0-14_linux64_openblas/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libsolv-0.7.19-h780b84a_5.tar.bz2\"\n",
      "Extracting \"botocore-1.26.10-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/botocore-1.26.10-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-pathtools-3.75-pl5321hec16e2b_3.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-pathtools-3.75-pl5321hec16e2b_3/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"ld_impl_linux-64-2.36.1-hea4e1c9_2.tar.bz2\"\n",
      "Extracting \"conda-package-handling-1.8.0-py39hb9d737c_0.tar.bz2\"\n",
      "Extracting \"humanfriendly-10.0-py310hff52083_2.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/humanfriendly-10.0-py310hff52083_2/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-carp-1.50-pl5321hd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-carp-1.50-pl5321hd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"retry-0.9.2-py_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/retry-0.9.2-py_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libstdcxx-ng-12.1.0-ha89aaad_16.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libstdcxx-ng-12.1.0-ha89aaad_16/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"brotli-bin-1.0.9-h166bdaf_7.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/brotli-bin-1.0.9-h166bdaf_7/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"xorg-inputproto-2.3.2-h7f98852_1002.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/xorg-inputproto-2.3.2-h7f98852_1002/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"pybind11-abi-4-hd8ed1ab_3.tar.bz2\"\n",
      "Extracting \"bcrypt-3.2.2-py37h540881e_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/bcrypt-3.2.2-py37h540881e_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"colorama-0.4.4-pyh9f0ad1d_0.tar.bz2\"\n",
      "Extracting \"libdeflate-1.10-h7f98852_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libdeflate-1.10-h7f98852_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"plac-1.3.5-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/plac-1.3.5-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"ca-certificates-2021.10.8-ha878542_0.tar.bz2\"\n",
      "Extracting \"perl-mime-base64-3.16-pl5321hec16e2b_2.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-mime-base64-3.16-pl5321hec16e2b_2/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"zlib-1.2.12-h166bdaf_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/zlib-1.2.12-h166bdaf_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"cffi-1.15.0-py310h0fdd8cc_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/cffi-1.15.0-py310h0fdd8cc_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"munkres-1.0.7-py_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/munkres-1.0.7-py_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"_openmp_mutex-4.5-2_gnu.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/_openmp_mutex-4.5-2_gnu/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"xorg-xproto-7.0.31-h7f98852_1007.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/xorg-xproto-7.0.31-h7f98852_1007/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"pysocks-1.7.1-py310hff52083_5.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/pysocks-1.7.1-py310hff52083_5/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libxml2-2.9.12-h885dcf4_1.tar.bz2\"\n",
      "Extracting \"pulp-2.6.0-py37h89c1867_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/pulp-2.6.0-py37h89c1867_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libffi-3.4.2-h7f98852_5.tar.bz2\"\n",
      "Extracting \"libxml2-2.9.12-h72842e0_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libxml2-2.9.12-h72842e0_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libiconv-1.16-h516909a_0.tar.bz2\"\n",
      "Extracting \"xz-5.2.5-h516909a_1.tar.bz2\"\n",
      "Extracting \"wheel-0.37.1-pyhd8ed1ab_0.tar.bz2\"\n",
      "Extracting \"freetype-2.10.4-h0708190_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/freetype-2.10.4-h0708190_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-alien-build-2.48-pl5321hec16e2b_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-alien-build-2.48-pl5321hec16e2b_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"alsa-lib-1.2.3.2-h166bdaf_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/alsa-lib-1.2.3.2-h166bdaf_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-exporter-5.74-pl5321hd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-exporter-5.74-pl5321hd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"font-ttf-inconsolata-3.000-h77eed37_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/font-ttf-inconsolata-3.000-h77eed37_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libev-4.33-h516909a_1.tar.bz2\"\n",
      "Extracting \"urllib3-1.26.9-pyhd8ed1ab_0.tar.bz2\"\n",
      "Extracting \"ftputil-5.0.4-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/ftputil-5.0.4-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libmamba-0.22.1-h9c208ef_0.tar.bz2\"\n",
      "Extracting \"importlib-metadata-4.11.4-py310hff52083_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/importlib-metadata-4.11.4-py310hff52083_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"parallel-fastq-dump-0.6.7-pyhdfd78af_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/parallel-fastq-dump-0.6.7-pyhdfd78af_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"python-3.10.4-h2660328_0_cpython.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/python-3.10.4-h2660328_0_cpython/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"xorg-fixesproto-5.0-h7f98852_1002.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/xorg-fixesproto-5.0-h7f98852_1002/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"zipp-3.8.0-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/zipp-3.8.0-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-xml-sax-base-1.09-pl5321hdfd78af_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-xml-sax-base-1.09-pl5321hdfd78af_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libjemalloc-5.2.1-h9c3ff4c_6.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libjemalloc-5.2.1-h9c3ff4c_6/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libblas-3.9.0-14_linux64_openblas.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libblas-3.9.0-14_linux64_openblas/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-capture-tiny-0.48-pl5321ha770c72_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-capture-tiny-0.48-pl5321ha770c72_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"certifi-2021.10.8-py39hf3d152e_1.tar.bz2\"\n",
      "Extracting \"pluggy-1.0.0-py37h89c1867_3.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/pluggy-1.0.0-py37h89c1867_3/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"llvmlite-0.36.0-py37h9d7f4d0_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/llvmlite-0.36.0-py37h9d7f4d0_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"dpath-2.0.6-py37h89c1867_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/dpath-2.0.6-py37h89c1867_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"xorg-libsm-1.2.3-hd9c2040_1000.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/xorg-libsm-1.2.3-hd9c2040_1000/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libgfortran-ng-12.1.0-h69a702a_16.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libgfortran-ng-12.1.0-h69a702a_16/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"fastqc-0.11.9-hdfd78af_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/fastqc-0.11.9-hdfd78af_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"coincbc-2.10.8-0_metapackage.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/coincbc-2.10.8-0_metapackage/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"boto3-1.23.10-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/boto3-1.23.10-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"openjdk-11.0.9.1-hc6918da_3.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/openjdk-11.0.9.1-hc6918da_3/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"xorg-libxau-1.0.9-h7f98852_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/xorg-libxau-1.0.9-h7f98852_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"requests-2.27.1-pyhd8ed1ab_0.tar.bz2\"\n",
      "Extracting \"jmespath-1.0.0-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/jmespath-1.0.0-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-data-dumper-2.183-pl5321hec16e2b_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-data-dumper-2.183-pl5321hec16e2b_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"paramiko-2.11.0-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/paramiko-2.11.0-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"harfbuzz-2.9.1-h83ec7ef_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/harfbuzz-2.9.1-h83ec7ef_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libxcb-1.13-h7f98852_1004.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libxcb-1.13-h7f98852_1004/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-file-temp-0.2304-pl5321hd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-file-temp-0.2304-pl5321hd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"xorg-libxtst-1.2.3-h7f98852_1002.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/xorg-libxtst-1.2.3-h7f98852_1002/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"filelock-3.7.0-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/filelock-3.7.0-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libglib-2.70.2-h174f98d_4.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libglib-2.70.2-h174f98d_4/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"icu-69.1-h9c3ff4c_0.tar.bz2\"\n",
      "Extracting \"ca-certificates-2022.5.18.1-ha878542_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/ca-certificates-2022.5.18.1-ha878542_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"charset-normalizer-2.0.12-pyhd8ed1ab_0.tar.bz2\"\n",
      "Extracting \"setuptools-60.10.0-py39hf3d152e_0.tar.bz2\"\n",
      "Extracting \"pycosat-0.6.3-py39h3811e60_1009.tar.bz2\"\n",
      "Extracting \"dataclasses-0.8-pyhc8e2a94_3.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/dataclasses-0.8-pyhc8e2a94_3/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"boost-cpp-1.74.0-h312852a_4.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/boost-cpp-1.74.0-h312852a_4/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libzlib-1.2.12-h166bdaf_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libzlib-1.2.12-h166bdaf_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"jinja2-3.1.2-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/jinja2-3.1.2-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"networkx-2.8.2-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/networkx-2.8.2-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-sub-info-0.002-pl5321hdfd78af_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-sub-info-0.002-pl5321hdfd78af_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libuuid-2.32.1-h7f98852_1000.tar.bz2\"\n",
      "Extracting \"yaml-cpp-0.6.3-he1b5a44_4.tar.bz2\"\n",
      "Extracting \"perl-importer-0.026-pl5321hdfd78af_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-importer-0.026-pl5321hdfd78af_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"zstd-1.5.2-h8a70e8d_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/zstd-1.5.2-h8a70e8d_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"ncbi-ngs-sdk-2.11.2-pl5321h629fbf0_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/ncbi-ngs-sdk-2.11.2-pl5321h629fbf0_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"markupsafe-2.1.1-py310h5764c6d_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/markupsafe-2.1.1-py310h5764c6d_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"xorg-kbproto-1.0.7-h7f98852_1002.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/xorg-kbproto-1.0.7-h7f98852_1002/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-file-path-2.18-pl5321hd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-file-path-2.18-pl5321hd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-parent-0.238-pl5321hd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-parent-0.238-pl5321hd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"openjdk-11.0.9.1-h5cc2fde_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/openjdk-11.0.9.1-h5cc2fde_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-encode-3.17-pl5321hec16e2b_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-encode-3.17-pl5321hec16e2b_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"font-ttf-source-code-pro-2.038-h77eed37_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/font-ttf-source-code-pro-2.038-h77eed37_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-path-tiny-0.122-pl5321hdfd78af_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-path-tiny-0.122-pl5321hdfd78af_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"snakemake-7.8.0-hdfd78af_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/snakemake-7.8.0-hdfd78af_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libnsl-2.0.0-h7f98852_0.tar.bz2\"\n",
      "Extracting \"cairo-1.16.0-ha61ee94_1011.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/cairo-1.16.0-ha61ee94_1011/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"graphite2-1.3.13-h58526e2_1001.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/graphite2-1.3.13-h58526e2_1001/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"expat-2.4.8-h27087fc_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/expat-2.4.8-h27087fc_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"veracitools-0.1.3-py_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/veracitools-0.1.3-py_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"lerc-3.0-h9c3ff4c_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/lerc-3.0-h9c3ff4c_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"numba-0.53.1-py37hb11d6e1_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/numba-0.53.1-py37hb11d6e1_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"numpy-1.22.4-py310h4ef5377_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/numpy-1.22.4-py310h4ef5377_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"brotlipy-0.7.0-py39h3811e60_1003.tar.bz2\"\n",
      "Extracting \"configargparse-1.5.3-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/configargparse-1.5.3-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libedit-3.1.20191231-he28a2e2_2.tar.bz2\"\n",
      "Extracting \"readline-8.1-h46c0cb4_0.tar.bz2\"\n",
      "Extracting \"pytest-7.1.2-py37h89c1867_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/pytest-7.1.2-py37h89c1867_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-file-which-1.24-pl5321hd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-file-which-1.24-pl5321hd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"boost-cpp-1.74.0-h6cacc03_7.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/boost-cpp-1.74.0-h6cacc03_7/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"hdf5-1.10.6-nompi_h6a2412b_1114.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/hdf5-1.10.6-nompi_h6a2412b_1114/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"smart_open-6.0.0-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/smart_open-6.0.0-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"openjpeg-2.4.0-hb52868f_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/openjpeg-2.4.0-hb52868f_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"logmuse-0.2.6-pyh8c360ce_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/logmuse-0.2.6-pyh8c360ce_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libpng-1.6.37-h21135ba_2.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libpng-1.6.37-h21135ba_2/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"amply-0.1.5-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/amply-0.1.5-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libopenblas-0.3.20-pthreads_h78a6416_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libopenblas-0.3.20-pthreads_h78a6416_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-5.32.1-2_h7f98852_perl5.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-5.32.1-2_h7f98852_perl5/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"colormath-3.0.0-py_2.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/colormath-3.0.0-py_2/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-alien-libxml2-0.17-pl5321hec16e2b_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-alien-libxml2-0.17-pl5321hec16e2b_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libcurl-7.82.0-h7bff187_0.tar.bz2\"\n",
      "Extracting \"ncurses-6.3-h9c3ff4c_0.tar.bz2\"\n",
      "Extracting \"pip-22.0.4-pyhd8ed1ab_0.tar.bz2\"\n",
      "Extracting \"brotli-1.0.9-h166bdaf_7.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/brotli-1.0.9-h166bdaf_7/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"trimmomatic-0.36-6.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/trimmomatic-0.36-6/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"pcre-8.45-h9c3ff4c_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/pcre-8.45-h9c3ff4c_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"curl-7.83.1-h7bff187_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/curl-7.83.1-h7bff187_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"sra-tools-2.11.0-pl5321ha49a11a_3.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/sra-tools-2.11.0-pl5321ha49a11a_3/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"future-0.18.2-py310hff52083_5.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/future-0.18.2-py310hff52083_5/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"harfbuzz-4.3.0-hf9f4e7c_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/harfbuzz-4.3.0-hf9f4e7c_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"pyopenssl-22.0.0-pyhd8ed1ab_0.tar.bz2\"\n",
      "Extracting \"_libgcc_mutex-0.1-conda_forge.tar.bz2\"\n",
      "Extracting \"libarchive-3.5.2-hccf745f_1.tar.bz2\"\n",
      "Extracting \"perl-xml-namespacesupport-1.12-pl5321hdfd78af_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-xml-namespacesupport-1.12-pl5321hdfd78af_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"setuptools-62.3.2-py310hff52083_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/setuptools-62.3.2-py310hff52083_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-business-isbn-data-20210112.006-pl5321hdfd78af_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-business-isbn-data-20210112.006-pl5321hdfd78af_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"jpeg-9e-h166bdaf_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/jpeg-9e-h166bdaf_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"tbb-2020.2-h4bd325d_4.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/tbb-2020.2-h4bd325d_4/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libbrotlidec-1.0.9-h166bdaf_7.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libbrotlidec-1.0.9-h166bdaf_7/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"sqlite-3.38.5-h4ff8645_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/sqlite-3.38.5-h4ff8645_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"toposort-1.7-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/toposort-1.7-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"coin-or-cbc-2.10.8-h3786ebc_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/coin-or-cbc-2.10.8-h3786ebc_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"krb5-1.19.3-h3790be6_0.tar.bz2\"\n",
      "Extracting \"lzo-2.10-h516909a_1000.tar.bz2\"\n",
      "Extracting \"perl-xml-libxml-2.0207-pl5321h661654b_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-xml-libxml-2.0207-pl5321h661654b_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"yte-1.4.0-py37h89c1867_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/yte-1.4.0-py37h89c1867_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"fontconfig-2.14.0-h8e229c2_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/fontconfig-2.14.0-h8e229c2_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"ply-3.11-py_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/ply-3.11-py_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"simplejson-3.17.6-py37h540881e_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/simplejson-3.17.6-py37h540881e_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"zlib-1.2.11-h36c2ea0_1013.tar.bz2\"\n",
      "Extracting \"libcblas-3.9.0-14_linux64_openblas.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libcblas-3.9.0-14_linux64_openblas/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libgomp-12.1.0-h8d9b700_16.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libgomp-12.1.0-h8d9b700_16/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"six-1.16.0-pyh6c4a22f_0.tar.bz2\"\n",
      "Extracting \"libllvm10-10.0.1-he513fc3_3.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libllvm10-10.0.1-he513fc3_3/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"keyutils-1.6.1-h166bdaf_0.tar.bz2\"\n",
      "Extracting \"xorg-libxext-1.3.4-h7f98852_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/xorg-libxext-1.3.4-h7f98852_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"oauth2client-4.1.3-py_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/oauth2client-4.1.3-py_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"sqlite-3.37.1-h4ff8645_0.tar.bz2\"\n",
      "Extracting \"python_abi-3.9-2_cp39.tar.bz2\"\n",
      "Extracting \"typing_extensions-4.2.0-pyha770c72_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/typing_extensions-4.2.0-pyha770c72_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"tabulate-0.8.9-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/tabulate-0.8.9-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"pynacl-1.5.0-py37h540881e_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/pynacl-1.5.0-py37h540881e_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"ncurses-6.3-h27087fc_1.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/ncurses-6.3-h27087fc_1/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"openssl-1.1.1l-h7f98852_0.tar.bz2\"\n",
      "Extracting \"lzstring-1.0.4-py_1001.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/lzstring-1.0.4-py_1001/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"s3transfer-0.5.2-pyhd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/s3transfer-0.5.2-pyhd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"krb5-1.19.3-h08a2579_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/krb5-1.19.3-h08a2579_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"tzdata-2022a-h191b570_0.tar.bz2\"\n",
      "Extracting \"xorg-libxdmcp-1.1.3-h7f98852_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/xorg-libxdmcp-1.1.3-h7f98852_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"ossuuid-1.6.2-hf484d3e_1000.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/ossuuid-1.6.2-hf484d3e_1000/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"coin-or-utils-2.11.6-h573740c_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/coin-or-utils-2.11.6-h573740c_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"perl-extutils-makemaker-7.64-pl5321hd8ed1ab_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/perl-extutils-makemaker-7.64-pl5321hd8ed1ab_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"xorg-libx11-1.7.2-h7f98852_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/xorg-libx11-1.7.2-h7f98852_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"multiqc-1.12-pyhdfd78af_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/multiqc-1.12-pyhdfd78af_0/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"libgcc-ng-12.1.0-h8d9b700_16.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/libgcc-ng-12.1.0-h8d9b700_16/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"peppy-0.31.2-pyhd8ed1ab_2.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/peppy-0.31.2-pyhd8ed1ab_2/info/repodata_record.json\"\n",
      "    \n",
      "Extracting \"entrez-direct-16.2-he881be0_0.tar.bz2\"\n",
      "\u001b[33m\u001b[1mwarning \u001b[m Failed to add extra info to \"/home/jupyter/mambaforge/pkgs/entrez-direct-16.2-he881be0_0/info/repodata_record.json\"\n",
      "    \n",
      "\n",
      "                                           __\n",
      "          __  ______ ___  ____ _____ ___  / /_  ____ _\n",
      "         / / / / __ `__ \\/ __ `/ __ `__ \\/ __ \\/ __ `/\n",
      "        / /_/ / / / / / / /_/ / / / / / / /_/ / /_/ /\n",
      "       / .___/_/ /_/ /_/\\__,_/_/ /_/ /_/_.___/\\__,_/\n",
      "      /_/\n",
      "\n",
      "conda-forge/linux-64                                        Using cache\n",
      "conda-forge/noarch                                          Using cache\n",
      "pkgs/main/linux-64                                          Using cache\n",
      "pkgs/main/noarch                                            Using cache\n",
      "pkgs/r/linux-64                                             Using cache\n",
      "pkgs/r/noarch                                               Using cache\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /home/jupyter/mambaforge\n",
      "\n",
      "  All requested packages already installed\n",
      "\n",
      "\n",
      "Transaction starting\n",
      "\u001b[?25l\u001b[2K\u001b[0G\u001b[?25hTransaction finished\n",
      "installation finished.\n",
      "16:08:32\n"
     ]
    }
   ],
   "source": [
    "!curl -L -O https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-$(uname)-$(uname -m).sh\n",
    "!bash Mambaforge-$(uname)-$(uname -m).sh -b -u -p $HOME/mambaforge\n",
    "!export PATH=\"$HOME/mambaforge/bin:$PATH\"\n",
    "!date +\"%T\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, using mambaforge and bioconda, install the tools that will be used in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  __    __    __    __\n",
      "                 /  \\  /  \\  /  \\  /  \\\n",
      "                /    \\/    \\/    \\/    \\\n",
      "/  //  //  //  /\n",
      "              /  / \\   / \\   / \\   / \\  \\____\n",
      "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
      "            / _/                       \\_____/  `\n",
      "            |/\n",
      "                  \n",
      "          \n",
      "        \n",
      "        \n",
      "                \n",
      "                       \n",
      "\n",
      "        mamba (0.22.1) supported by @QuantStack\n",
      "\n",
      "        GitHub:  https://github.com/mamba-org/mamba\n",
      "        Twitter: https://twitter.com/QuantStack\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Looking for: ['trimmomatic']\n",
      "\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "bioconda/linux-64    \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "bioconda/noarch      \u001b[90m\u001b[0m\u001b[33m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "pkgs/main/linux-64   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/linux-64                                            No change\n",
      "[+] 0.2s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\n",
      "bioconda/linux-64    \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\n",
      "bioconda/noarch      \u001b[90m\u001b[0m\u001b[33m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\n",
      "pkgs/r/noarch        \u001b[90m\u001b[0m\u001b[33m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/r/noarch                                                 No change\n",
      "bioconda/noarch                                               No change\n",
      "bioconda/linux-64                                             No change\n",
      "pkgs/main/noarch                                              No change\n",
      "pkgs/r/linux-64                                               No change\n",
      "[+] 0.3s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m 355.8kB /  ??.?MB @   1.3MB/s  0.3s\n",
      "conda-forge/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m 296.4kB /  ??.?MB @   1.1MB/s  0.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.4s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m 883.0kB /  ??.?MB @   2.4MB/s  0.4s\n",
      "conda-forge/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m 768.1kB /  ??.?MB @   2.1MB/s  0.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.5s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   1.4MB /  ??.?MB @   3.0MB/s  0.5s\n",
      "conda-forge/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   1.3MB /  ??.?MB @   2.9MB/s  0.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.6s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   1.9MB /  ??.?MB @   3.4MB/s  0.6s\n",
      "conda-forge/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   1.8MB /  ??.?MB @   3.2MB/s  0.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.7s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m   2.5MB /  ??.?MB @   3.7MB/s  0.7s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   2.3MB /  ??.?MB @   3.4MB/s  0.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.8s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m   3.0MB /  ??.?MB @   3.9MB/s  0.8s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   2.8MB /  ??.?MB @   3.7MB/s  0.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.9s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m   3.5MB /  ??.?MB @   4.1MB/s  0.9s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m   3.3MB /  ??.?MB @   3.8MB/s  0.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.0s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m   4.1MB /  ??.?MB @   4.2MB/s  1.0s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m   3.8MB /  ??.?MB @   3.9MB/s  1.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.1s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m   4.6MB /  ??.?MB @   4.3MB/s  1.1s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m   4.4MB /  ??.?MB @   4.1MB/s  1.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.2s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m   5.2MB /  ??.?MB @   4.4MB/s  1.2s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m   4.8MB /  ??.?MB @   4.1MB/s  1.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.3s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m   5.7MB /  ??.?MB @   4.5MB/s  1.3s\n",
      "conda-forge/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   5.4MB /  ??.?MB @   4.2MB/s  1.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.4s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   6.2MB /  ??.?MB @   4.5MB/s  1.4s\n",
      "conda-forge/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   5.9MB /  ??.?MB @   4.3MB/s  1.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.5s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   6.7MB /  ??.?MB @   4.6MB/s  1.5s\n",
      "conda-forge/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   6.4MB /  ??.?MB @   4.3MB/s  1.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.6s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   7.2MB /  ??.?MB @   4.6MB/s  1.6s\n",
      "conda-forge/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   6.9MB /  ??.?MB @   4.4MB/s  1.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.7s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m   7.8MB /  ??.?MB @   4.6MB/s  1.7s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   7.4MB /  ??.?MB @   4.4MB/s  1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.8s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m   8.3MB /  ??.?MB @   4.6MB/s  1.8s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   7.9MB /  ??.?MB @   4.4MB/s  1.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.9s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m   8.5MB /  ??.?MB @   4.6MB/s  1.9s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   8.1MB /  ??.?MB @   4.5MB/s  1.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.0s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m   8.5MB /  ??.?MB @   4.6MB/s  2.0s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   8.1MB /  ??.?MB @   4.5MB/s  2.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.1s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m   8.5MB /  ??.?MB @   4.6MB/s  2.1s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   8.1MB /  ??.?MB @   4.5MB/s  2.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.2s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m   8.5MB @   4.6MB/s             2.2s\n",
      "conda-forge/noarch      8.3MB @   4.5MB/s Finalizing  2.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.3s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m   8.5MB /  ??.?MB @   4.6MB/s  2.3s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.4s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m   8.5MB /  ??.?MB @   4.6MB/s  2.4s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.5s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m   8.5MB /  ??.?MB @   4.6MB/s  2.5s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.6s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m   8.5MB /  ??.?MB @   4.6MB/s  2.6s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/noarch                                 @   4.5MB/s  2.2s\n",
      "[+] 2.7s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m  10.0MB /  ??.?MB @   3.8MB/s  2.7s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.8s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  11.4MB /  ??.?MB @   4.1MB/s  2.8s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.9s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  11.9MB /  ??.?MB @   4.2MB/s  2.9s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.0s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  12.4MB /  ??.?MB @   4.2MB/s  3.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.1s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  12.9MB /  ??.?MB @   4.2MB/s  3.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.2s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m  13.4MB /  ??.?MB @   4.3MB/s  3.2s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.3s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m  14.0MB /  ??.?MB @   4.3MB/s  3.3s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.4s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m  14.4MB /  ??.?MB @   4.3MB/s  3.4s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.5s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m  14.9MB /  ??.?MB @   4.3MB/s  3.5s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.6s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m  15.4MB /  ??.?MB @   4.3MB/s  3.6s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.7s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m  15.9MB /  ??.?MB @   4.3MB/s  3.7s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.8s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m  16.0MB /  ??.?MB @   4.2MB/s  3.8s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.9s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  17.1MB /  ??.?MB @   4.4MB/s  3.9s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.0s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  17.6MB /  ??.?MB @   4.4MB/s  4.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.1s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  18.1MB /  ??.?MB @   4.4MB/s  4.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.2s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  18.3MB /  ??.?MB @   4.4MB/s  4.2s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.3s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m  18.9MB /  ??.?MB @   4.4MB/s  4.3s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.4s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m  19.4MB /  ??.?MB @   4.5MB/s  4.4s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.5s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m  19.9MB /  ??.?MB @   4.5MB/s  4.5s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.6s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m  20.4MB /  ??.?MB @   4.5MB/s  4.6s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.7s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m  21.0MB /  ??.?MB @   4.5MB/s  4.7s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.8s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m  21.5MB /  ??.?MB @   4.5MB/s  4.8s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.9s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  22.1MB /  ??.?MB @   4.5MB/s  4.9s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.0s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  22.6MB /  ??.?MB @   4.6MB/s  5.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.1s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  23.1MB /  ??.?MB @   4.6MB/s  5.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.2s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  23.1MB /  ??.?MB @   4.6MB/s  5.2s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.3s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  23.1MB /  ??.?MB @   4.6MB/s  5.3s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.4s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  23.1MB /  ??.?MB @   4.6MB/s  5.4s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.5s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  23.1MB /  ??.?MB @   4.6MB/s  5.5s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.6s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  23.1MB /  ??.?MB @   4.6MB/s  5.6s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.7s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  23.1MB /  ??.?MB @   4.6MB/s  5.7s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.8s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  23.1MB /  ??.?MB @   4.6MB/s  5.8s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.9s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  23.1MB /  ??.?MB @   4.6MB/s  5.9s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.0s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  23.1MB /  ??.?MB @   4.6MB/s  6.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.1s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  23.1MB /  ??.?MB @   4.6MB/s  6.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.2s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  23.1MB /  ??.?MB @   4.6MB/s  6.2s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.3s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  23.1MB /  ??.?MB @   4.6MB/s  6.3s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.4s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  23.1MB /  ??.?MB @   4.6MB/s  6.4s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.5s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  23.1MB /  ??.?MB @   4.6MB/s  6.5s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.6s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  23.1MB /  ??.?MB @   4.6MB/s  6.6s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.7s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  23.1MB /  ??.?MB @   4.6MB/s  6.7s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.8s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  23.1MB /  ??.?MB @   4.6MB/s  6.8s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.9s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  23.1MB /  ??.?MB @   4.6MB/s  6.9s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.0s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  23.1MB /  ??.?MB @   4.6MB/s  7.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.1s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  23.1MB /  ??.?MB @   4.6MB/s  7.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.2s\n",
      "conda-forge/linux-64   23.3MB @   4.6MB/s Finalizing  7.2s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.3s\n",
      "conda-forge/linux-64   23.3MB @   4.6MB/s Finalizing  7.3s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.4s\n",
      "conda-forge/linux-64   23.3MB @   4.6MB/s Finalizing  7.4s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.5s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.6s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.7s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.8s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.9s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.1s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.2s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.3s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.4s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.5s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.6s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.7s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.8s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/linux-64                               @   4.6MB/s  7.4s\n",
      "\u001b[?25h\n",
      "Pinned packages:\n",
      "  - python 3.7.*\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /opt/conda\n",
      "\n",
      "  All requested packages already installed\n",
      "\n",
      "\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\n",
      "                  __    __    __    __\n",
      "                 /  \\  /  \\  /  \\  /  \\\n",
      "                /    \\/    \\/    \\/    \\\n",
      "/  //  //  //  /\n",
      "              /  / \\   / \\   / \\   / \\  \\____\n",
      "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
      "            / _/                       \\_____/  `\n",
      "            |/\n",
      "                  \n",
      "          \n",
      "        \n",
      "        \n",
      "                \n",
      "                       \n",
      "\n",
      "        mamba (0.22.1) supported by @QuantStack\n",
      "\n",
      "        GitHub:  https://github.com/mamba-org/mamba\n",
      "        Twitter: https://twitter.com/QuantStack\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Looking for: ['fastqc']\n",
      "\n",
      "conda-forge/linux-64                                        Using cache\n",
      "conda-forge/noarch                                          Using cache\n",
      "bioconda/linux-64                                           Using cache\n",
      "bioconda/noarch                                             Using cache\n",
      "pkgs/main/linux-64                                          Using cache\n",
      "pkgs/main/noarch                                            Using cache\n",
      "pkgs/r/linux-64                                             Using cache\n",
      "pkgs/r/noarch                                               Using cache\n",
      "\n",
      "Pinned packages:\n",
      "  - python 3.7.*\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /opt/conda\n",
      "\n",
      "  All requested packages already installed\n",
      "\n",
      "\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\n",
      "                  __    __    __    __\n",
      "                 /  \\  /  \\  /  \\  /  \\\n",
      "                /    \\/    \\/    \\/    \\\n",
      "/  //  //  //  /\n",
      "              /  / \\   / \\   / \\   / \\  \\____\n",
      "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
      "            / _/                       \\_____/  `\n",
      "            |/\n",
      "                  \n",
      "          \n",
      "        \n",
      "        \n",
      "                \n",
      "                       \n",
      "\n",
      "        mamba (0.22.1) supported by @QuantStack\n",
      "\n",
      "        GitHub:  https://github.com/mamba-org/mamba\n",
      "        Twitter: https://twitter.com/QuantStack\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Looking for: ['multiqc']\n",
      "\n",
      "conda-forge/linux-64                                        Using cache\n",
      "conda-forge/noarch                                          Using cache\n",
      "bioconda/linux-64                                           Using cache\n",
      "bioconda/noarch                                             Using cache\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
      "pkgs/main/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "pkgs/main/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "pkgs/r/linux-64    \u001b[90m\u001b[0m\u001b[33m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "pkgs/r/noarch      \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.2s\n",
      "pkgs/main/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\n",
      "pkgs/main/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\n",
      "pkgs/r/linux-64    \u001b[90m\u001b[0m\u001b[33m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\n",
      "pkgs/r/noarch      \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/linux-64                                            No change\n",
      "pkgs/main/noarch                                              No change\n",
      "pkgs/r/linux-64                                               No change\n",
      "pkgs/r/noarch                                                 No change\n",
      "[+] 0.3s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25h\n",
      "Pinned packages:\n",
      "  - python 3.7.*\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /opt/conda\n",
      "\n",
      "  All requested packages already installed\n",
      "\n",
      "\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\n",
      "                  __    __    __    __\n",
      "                 /  \\  /  \\  /  \\  /  \\\n",
      "                /    \\/    \\/    \\/    \\\n",
      "/  //  //  //  /\n",
      "              /  / \\   / \\   / \\   / \\  \\____\n",
      "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
      "            / _/                       \\_____/  `\n",
      "            |/\n",
      "                  \n",
      "          \n",
      "        \n",
      "        \n",
      "                \n",
      "                       \n",
      "\n",
      "        mamba (0.22.1) supported by @QuantStack\n",
      "\n",
      "        GitHub:  https://github.com/mamba-org/mamba\n",
      "        Twitter: https://twitter.com/QuantStack\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Looking for: ['salmon']\n",
      "\n",
      "conda-forge/linux-64                                        Using cache\n",
      "conda-forge/noarch                                          Using cache\n",
      "bioconda/linux-64                                           Using cache\n",
      "bioconda/noarch                                             Using cache\n",
      "pkgs/main/linux-64                                          Using cache\n",
      "pkgs/main/noarch                                            Using cache\n",
      "pkgs/r/linux-64                                             Using cache\n",
      "pkgs/r/noarch                                               Using cache\n",
      "\n",
      "Pinned packages:\n",
      "  - python 3.7.*\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /opt/conda\n",
      "\n",
      "  All requested packages already installed\n",
      "\n",
      "\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\n",
      "                  __    __    __    __\n",
      "                 /  \\  /  \\  /  \\  /  \\\n",
      "                /    \\/    \\/    \\/    \\\n",
      "/  //  //  //  /\n",
      "              /  / \\   / \\   / \\   / \\  \\____\n",
      "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
      "            / _/                       \\_____/  `\n",
      "            |/\n",
      "                  \n",
      "          \n",
      "        \n",
      "        \n",
      "                \n",
      "                       \n",
      "\n",
      "        mamba (0.22.1) supported by @QuantStack\n",
      "\n",
      "        GitHub:  https://github.com/mamba-org/mamba\n",
      "        Twitter: https://twitter.com/QuantStack\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Looking for: ['sra-tools']\n",
      "\n",
      "conda-forge/linux-64                                        Using cache\n",
      "conda-forge/noarch                                          Using cache\n",
      "bioconda/linux-64                                           Using cache\n",
      "bioconda/noarch                                             Using cache\n",
      "pkgs/main/linux-64                                          Using cache\n",
      "pkgs/main/noarch                                            Using cache\n",
      "pkgs/r/linux-64                                             Using cache\n",
      "pkgs/r/noarch                                               Using cache\n",
      "\n",
      "Pinned packages:\n",
      "  - python 3.7.*\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /opt/conda\n",
      "\n",
      "  All requested packages already installed\n",
      "\n",
      "\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\n",
      "                  __    __    __    __\n",
      "                 /  \\  /  \\  /  \\  /  \\\n",
      "                /    \\/    \\/    \\/    \\\n",
      "/  //  //  //  /\n",
      "              /  / \\   / \\   / \\   / \\  \\____\n",
      "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
      "            / _/                       \\_____/  `\n",
      "            |/\n",
      "                  \n",
      "          \n",
      "        \n",
      "        \n",
      "                \n",
      "                       \n",
      "\n",
      "        mamba (0.22.1) supported by @QuantStack\n",
      "\n",
      "        GitHub:  https://github.com/mamba-org/mamba\n",
      "        Twitter: https://twitter.com/QuantStack\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Looking for: ['parallel-fastq-dump']\n",
      "\n",
      "conda-forge/linux-64                                        Using cache\n",
      "conda-forge/noarch                                          Using cache\n",
      "bioconda/linux-64                                           Using cache\n",
      "bioconda/noarch                                             Using cache\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "pkgs/main/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
      "pkgs/main/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "pkgs/main/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "pkgs/r/linux-64    \u001b[90m\u001b[0m\u001b[33m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "pkgs/r/noarch      \u001b[90m\u001b[0m\u001b[33m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/r/noarch                                                 No change\n",
      "pkgs/r/linux-64                                               No change\n",
      "pkgs/main/linux-64                                            No change\n",
      "pkgs/main/noarch                                              No change\n",
      "\u001b[?25h\n",
      "Pinned packages:\n",
      "  - python 3.7.*\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /opt/conda\n",
      "\n",
      "  All requested packages already installed\n",
      "\n",
      "\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\n",
      "                  __    __    __    __\n",
      "                 /  \\  /  \\  /  \\  /  \\\n",
      "                /    \\/    \\/    \\/    \\\n",
      "/  //  //  //  /\n",
      "              /  / \\   / \\   / \\   / \\  \\____\n",
      "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
      "            / _/                       \\_____/  `\n",
      "            |/\n",
      "                  \n",
      "          \n",
      "        \n",
      "        \n",
      "                \n",
      "                       \n",
      "\n",
      "        mamba (0.22.1) supported by @QuantStack\n",
      "\n",
      "        GitHub:  https://github.com/mamba-org/mamba\n",
      "        Twitter: https://twitter.com/QuantStack\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Looking for: ['entrez-direct']\n",
      "\n",
      "conda-forge/linux-64                                        Using cache\n",
      "conda-forge/noarch                                          Using cache\n",
      "bioconda/linux-64                                           Using cache\n",
      "bioconda/noarch                                             Using cache\n",
      "pkgs/main/linux-64                                          Using cache\n",
      "pkgs/main/noarch                                            Using cache\n",
      "pkgs/r/linux-64                                             Using cache\n",
      "pkgs/r/noarch                                               Using cache\n",
      "\n",
      "Pinned packages:\n",
      "  - python 3.7.*\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /opt/conda\n",
      "\n",
      "  All requested packages already installed\n",
      "\n",
      "\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\n",
      "                  __    __    __    __\n",
      "                 /  \\  /  \\  /  \\  /  \\\n",
      "                /    \\/    \\/    \\/    \\\n",
      "/  //  //  //  /\n",
      "              /  / \\   / \\   / \\   / \\  \\____\n",
      "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
      "            / _/                       \\_____/  `\n",
      "            |/\n",
      "                  \n",
      "          \n",
      "        \n",
      "        \n",
      "                \n",
      "                       \n",
      "\n",
      "        mamba (0.22.1) supported by @QuantStack\n",
      "\n",
      "        GitHub:  https://github.com/mamba-org/mamba\n",
      "        Twitter: https://twitter.com/QuantStack\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Looking for: ['gffread']\n",
      "\n",
      "conda-forge/linux-64                                        Using cache\n",
      "conda-forge/noarch                                          Using cache\n",
      "bioconda/linux-64                                           Using cache\n",
      "bioconda/noarch                                             Using cache\n",
      "pkgs/main/linux-64                                          Using cache\n",
      "pkgs/main/noarch                                            Using cache\n",
      "pkgs/r/linux-64                                             Using cache\n",
      "pkgs/r/noarch                                               Using cache\n",
      "\n",
      "Pinned packages:\n",
      "  - python 3.7.*\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /opt/conda\n",
      "\n",
      "  All requested packages already installed\n",
      "\n",
      "\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!$HOME/mambaforge/bin/mamba install -y -c conda-forge -c bioconda trimmomatic\n",
    "!$HOME/mambaforge/bin/mamba install -y -c conda-forge -c bioconda fastqc\n",
    "!$HOME/mambaforge/bin/mamba install -y -c conda-forge -c bioconda multiqc\n",
    "!$HOME/mambaforge/bin/mamba install -y -c conda-forge -c bioconda salmon\n",
    "!$HOME/mambaforge/bin/mamba install -y -c conda-forge -c bioconda sra-tools\n",
    "!$HOME/mambaforge/bin/mamba install -y -c conda-forge -c bioconda parallel-fastq-dump\n",
    "!$HOME/mambaforge/bin/mamba install -y -c conda-forge -c bioconda entrez-direct\n",
    "!$HOME/mambaforge/bin/mamba install -y -c conda-forge -c bioconda gffread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a set of directories to store the reads, reference sequence files, and output files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/rnaseq-myco-notebook\n"
     ]
    }
   ],
   "source": [
    "!cd $HOMEDIR\n",
    "!echo $PWD\n",
    "!mkdir -p data\n",
    "!mkdir -p data/raw_fastq\n",
    "!mkdir -p data/trimmed\n",
    "!mkdir -p data/fastqc\n",
    "!mkdir -p data/aligned\n",
    "!mkdir -p data/reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP 3: Downloading relevant FASTQ files using SRA Tools\n",
    "\n",
    "Next we will need to download the relevant fastq files.\n",
    "\n",
    "The sequence data for this tutorial comes from work by Cushman et al., <em><a href='https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8191103/'>Increased whiB7 expression and antibiotic resistance in Mycobacterium chelonae carrying two prophages</a><em>.\n",
    "\n",
    "We will be downloading the sample runs from this project using SRA tools, downloading from the NCBI's SRA (Sequence Run Archives).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3.1: Finding run accession numbers.\n",
    "\n",
    "The SRA stores sequence data in terms of runs, (SRR stands for Sequence Read Run). To download runs, we will need the accession ID for each run we wish to download. \n",
    "\n",
    "The Cushman et al., project contains 12 runs. To make it easier, these are the run IDs associated with this project:\n",
    "\n",
    "SRR13349122\n",
    "SRR13349123\n",
    "SRR13349124\n",
    "SRR13349125\n",
    "SRR13349126\n",
    "SRR13349127\n",
    "SRR13349128\n",
    "SRR13349129\n",
    "SRR13349130\n",
    "SRR13349131\n",
    "SRR13349132\n",
    "SRR13349133\n",
    "\n",
    "\n",
    "In this case, all these runs belong to the SRP (Sequence Run Project): SRP300216.\n",
    "\n",
    "Sequence run experiments can be searched for using the SRA database on the NCBI website; and article specific sample run information can be found in the supplementary section of that article.\n",
    "\n",
    "For instance, here, the the authors posted a link to the sequence data GSE (Gene Series number), <a href='https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE164210'>GSE164210</a>. This leads to the appropriate 'Gene Expression Omnibus' page where, among other useful files and information, the relevant SRA database link can be found. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3.2: Using the SRA-toolkit.\n",
    "\n",
    "Now use the Sequence Run accession ID to download the sequence data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:10:17\n",
      "\n",
      "2022-05-30T00:10:17 prefetch.2.11.0: 1) Downloading 'SRR13349122'...\n",
      "2022-05-30T00:10:17 prefetch.2.11.0:  Downloading via HTTPS...\n",
      "2022-05-30T00:10:32 prefetch.2.11.0:  HTTPS download succeed\n",
      "2022-05-30T00:10:34 prefetch.2.11.0:  'SRR13349122' is valid\n",
      "2022-05-30T00:10:34 prefetch.2.11.0: 1) 'SRR13349122' was downloaded successfully\n",
      "2022-05-30T00:10:34 prefetch.2.11.0: 'SRR13349122' has 0 unresolved dependencies\n",
      "00:10:34\n"
     ]
    }
   ],
   "source": [
    "!prefetch  -O data/raw_fastq/ SRR13349122"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the SRA archives sequence files in the SRA format. \n",
    "\n",
    "Typically genome workflows processed data in the form of zipped or unzipped .fastq, or .fasta files\n",
    "\n",
    "So before we move on, we need to convert the files from .sra to .fastq using the fastq-dump tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 10827590 spots for data/raw_fastq/SRR13349122\n",
      "Written 10827590 spots for data/raw_fastq/SRR13349122\n",
      "00:16:25\n"
     ]
    }
   ],
   "source": [
    "#paired-end reads use the --split-files flag.\n",
    "#to save space, convert to a zipped fastq file with the --gzip flag.\n",
    "!fastq-dump -O data/raw_fastq/ --split-files --gzip data/raw_fastq/SRR13349122"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP 3.3 Downloading multiple files using the SRA-toolkit.\n",
    "\n",
    "One may, as in our case, wish to download multiple runs at once.\n",
    "\n",
    "To aid in this, SRA-tools supports batch downloading.\n",
    "\n",
    "We can download multiple SRA files using a single line of code by creating a list of the SRA IDs we wish to download, and inputting that into the prefetch command.\n",
    "\n",
    "For instance, one can first create a list of the 12 accession IDs for this project however they wish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRR13349122\n",
      "SRR13349123\n",
      "SRR13349124\n",
      "SRR13349125\n",
      "SRR13349126\n",
      "SRR13349127\n",
      "SRR13349128\n",
      "SRR13349129\n",
      "SRR13349130\n",
      "SRR13349131\n",
      "SRR13349132\n",
      "SRR13349133\n"
     ]
    }
   ],
   "source": [
    "!for i in {22..33}; do echo \"SRR133491$i\"; done > data/raw_fastq/list_of_accesionIDS.txt\n",
    "!cat data/raw_fastq/list_of_accesionIDS.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then feed that list into the sra-toolkit prefetch command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:25:14\n",
      "\n",
      "2022-05-30T00:25:15 prefetch.2.11.0: 1) Downloading 'SRR13349122'...\n",
      "2022-05-30T00:25:15 prefetch.2.11.0:  Downloading via HTTPS...\n",
      "2022-05-30T00:25:32 prefetch.2.11.0:  HTTPS download succeed\n",
      "2022-05-30T00:25:34 prefetch.2.11.0:  'SRR13349122' is valid\n",
      "2022-05-30T00:25:34 prefetch.2.11.0: 1) 'SRR13349122' was downloaded successfully\n",
      "2022-05-30T00:25:34 prefetch.2.11.0: 'SRR13349122' has 0 unresolved dependencies\n",
      "\n",
      "2022-05-30T00:25:35 prefetch.2.11.0: 2) Downloading 'SRR13349123'...\n",
      "2022-05-30T00:25:35 prefetch.2.11.0:  Downloading via HTTPS...\n",
      "2022-05-30T00:25:51 prefetch.2.11.0:  HTTPS download succeed\n",
      "2022-05-30T00:25:53 prefetch.2.11.0:  'SRR13349123' is valid\n",
      "2022-05-30T00:25:53 prefetch.2.11.0: 2) 'SRR13349123' was downloaded successfully\n",
      "2022-05-30T00:25:53 prefetch.2.11.0: 'SRR13349123' has 0 unresolved dependencies\n",
      "\n",
      "2022-05-30T00:25:54 prefetch.2.11.0: 3) Downloading 'SRR13349124'...\n",
      "2022-05-30T00:25:54 prefetch.2.11.0:  Downloading via HTTPS...\n",
      "2022-05-30T00:26:12 prefetch.2.11.0:  HTTPS download succeed\n",
      "2022-05-30T00:26:14 prefetch.2.11.0:  'SRR13349124' is valid\n",
      "2022-05-30T00:26:14 prefetch.2.11.0: 3) 'SRR13349124' was downloaded successfully\n",
      "2022-05-30T00:26:14 prefetch.2.11.0: 'SRR13349124' has 0 unresolved dependencies\n",
      "\n",
      "2022-05-30T00:26:14 prefetch.2.11.0: 4) Downloading 'SRR13349125'...\n",
      "2022-05-30T00:26:14 prefetch.2.11.0:  Downloading via HTTPS...\n",
      "2022-05-30T00:26:32 prefetch.2.11.0:  HTTPS download succeed\n",
      "2022-05-30T00:26:33 prefetch.2.11.0:  'SRR13349125' is valid\n",
      "2022-05-30T00:26:33 prefetch.2.11.0: 4) 'SRR13349125' was downloaded successfully\n",
      "2022-05-30T00:26:33 prefetch.2.11.0: 'SRR13349125' has 0 unresolved dependencies\n",
      "\n",
      "2022-05-30T00:26:34 prefetch.2.11.0: 5) Downloading 'SRR13349126'...\n",
      "2022-05-30T00:26:34 prefetch.2.11.0:  Downloading via HTTPS...\n",
      "2022-05-30T00:26:52 prefetch.2.11.0:  HTTPS download succeed\n",
      "2022-05-30T00:26:54 prefetch.2.11.0:  'SRR13349126' is valid\n",
      "2022-05-30T00:26:54 prefetch.2.11.0: 5) 'SRR13349126' was downloaded successfully\n",
      "2022-05-30T00:26:54 prefetch.2.11.0: 'SRR13349126' has 0 unresolved dependencies\n",
      "\n",
      "2022-05-30T00:26:55 prefetch.2.11.0: 6) Downloading 'SRR13349127'...\n",
      "2022-05-30T00:26:55 prefetch.2.11.0:  Downloading via HTTPS...\n",
      "2022-05-30T00:27:14 prefetch.2.11.0:  HTTPS download succeed\n",
      "2022-05-30T00:27:16 prefetch.2.11.0:  'SRR13349127' is valid\n",
      "2022-05-30T00:27:16 prefetch.2.11.0: 6) 'SRR13349127' was downloaded successfully\n",
      "2022-05-30T00:27:16 prefetch.2.11.0: 'SRR13349127' has 0 unresolved dependencies\n",
      "\n",
      "2022-05-30T00:27:16 prefetch.2.11.0: 7) Downloading 'SRR13349128'...\n",
      "2022-05-30T00:27:16 prefetch.2.11.0:  Downloading via HTTPS...\n",
      "2022-05-30T00:27:35 prefetch.2.11.0:  HTTPS download succeed\n",
      "2022-05-30T00:27:36 prefetch.2.11.0:  'SRR13349128' is valid\n",
      "2022-05-30T00:27:36 prefetch.2.11.0: 7) 'SRR13349128' was downloaded successfully\n",
      "2022-05-30T00:27:36 prefetch.2.11.0: 'SRR13349128' has 0 unresolved dependencies\n",
      "\n",
      "2022-05-30T00:27:37 prefetch.2.11.0: 8) Downloading 'SRR13349129'...\n",
      "2022-05-30T00:27:37 prefetch.2.11.0:  Downloading via HTTPS...\n",
      "2022-05-30T00:27:56 prefetch.2.11.0:  HTTPS download succeed\n",
      "2022-05-30T00:27:57 prefetch.2.11.0:  'SRR13349129' is valid\n",
      "2022-05-30T00:27:57 prefetch.2.11.0: 8) 'SRR13349129' was downloaded successfully\n",
      "2022-05-30T00:27:57 prefetch.2.11.0: 'SRR13349129' has 0 unresolved dependencies\n",
      "\n",
      "2022-05-30T00:27:58 prefetch.2.11.0: 9) Downloading 'SRR13349130'...\n",
      "2022-05-30T00:27:58 prefetch.2.11.0:  Downloading via HTTPS...\n",
      "2022-05-30T00:28:15 prefetch.2.11.0:  HTTPS download succeed\n",
      "2022-05-30T00:28:16 prefetch.2.11.0:  'SRR13349130' is valid\n",
      "2022-05-30T00:28:16 prefetch.2.11.0: 9) 'SRR13349130' was downloaded successfully\n",
      "2022-05-30T00:28:16 prefetch.2.11.0: 'SRR13349130' has 0 unresolved dependencies\n",
      "\n",
      "2022-05-30T00:28:17 prefetch.2.11.0: 10) Downloading 'SRR13349131'...\n",
      "2022-05-30T00:28:17 prefetch.2.11.0:  Downloading via HTTPS...\n",
      "2022-05-30T00:28:33 prefetch.2.11.0:  HTTPS download succeed\n",
      "2022-05-30T00:28:34 prefetch.2.11.0:  'SRR13349131' is valid\n",
      "2022-05-30T00:28:34 prefetch.2.11.0: 10) 'SRR13349131' was downloaded successfully\n",
      "2022-05-30T00:28:34 prefetch.2.11.0: 'SRR13349131' has 0 unresolved dependencies\n",
      "\n",
      "2022-05-30T00:28:35 prefetch.2.11.0: 11) Downloading 'SRR13349132'...\n",
      "2022-05-30T00:28:35 prefetch.2.11.0:  Downloading via HTTPS...\n",
      "2022-05-30T00:28:52 prefetch.2.11.0:  HTTPS download succeed\n",
      "2022-05-30T00:28:54 prefetch.2.11.0:  'SRR13349132' is valid\n",
      "2022-05-30T00:28:54 prefetch.2.11.0: 11) 'SRR13349132' was downloaded successfully\n",
      "2022-05-30T00:28:54 prefetch.2.11.0: 'SRR13349132' has 0 unresolved dependencies\n",
      "\n",
      "2022-05-30T00:28:54 prefetch.2.11.0: 12) Downloading 'SRR13349133'...\n",
      "2022-05-30T00:28:54 prefetch.2.11.0:  Downloading via HTTPS...\n",
      "2022-05-30T00:29:10 prefetch.2.11.0:  HTTPS download succeed\n",
      "2022-05-30T00:29:12 prefetch.2.11.0:  'SRR13349133' is valid\n",
      "2022-05-30T00:29:12 prefetch.2.11.0: 12) 'SRR13349133' was downloaded successfully\n",
      "2022-05-30T00:29:12 prefetch.2.11.0: 'SRR13349133' has 0 unresolved dependencies\n",
      "00:29:12\n"
     ]
    }
   ],
   "source": [
    "!prefetch -O data/raw_fastq/ --option-file data/raw_fastq/list_of_accesionIDS.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3.3 Converting Multiple SRA files to Fastq\n",
    "\n",
    "Fastq-dump does not have native batch compatibility.\n",
    "\n",
    "There are various ways to get around this, for instance, commonly by using bash pipes or for-loops.\n",
    "\n",
    "One can also attempt to speed up the process of converting SRA to fastq files, by using fasterq-dump from the SRA-Tools library, or 'parallel-fastq-dump' from the separate parralel-fastq-dump library.\n",
    "\n",
    "There is more than one right way to do anything, but parallel-fastq-dump has the benefit of automatic zipping, whereas fasterq-dump does not have --gzip flag.\n",
    "\n",
    "Below is an example of one way to batch convert SRA to fastq files, piping in the same accession list used to download the SRAs with prefetech.\n",
    "\n",
    "The below code may take approximately 30 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-29 16:16:19,217 - SRR ids: ['SRR13349122']\n",
      "2022-05-29 16:16:19,217 - extra args: ['--gzip', '--split-files']\n",
      "2022-05-29 16:16:19,258 - tempdir: ./pfd_j9vlf9o7\n",
      "2022-05-29 16:16:19,259 - CMD: sra-stat --meta --quick SRR13349122\n",
      "2022-05-29 16:16:23,127 - SRR13349122 spots: 10827590\n",
      "2022-05-29 16:16:23,128 - blocks: [[1, 1353448], [1353449, 2706896], [2706897, 4060344], [4060345, 5413792], [5413793, 6767240], [6767241, 8120688], [8120689, 9474136], [9474137, 10827590]]\n",
      "2022-05-29 16:16:23,129 - CMD: fastq-dump -N 1 -X 1353448 -O ./pfd_j9vlf9o7/0 --gzip --split-files SRR13349122\n",
      "2022-05-29 16:16:23,130 - CMD: fastq-dump -N 1353449 -X 2706896 -O ./pfd_j9vlf9o7/1 --gzip --split-files SRR13349122\n",
      "2022-05-29 16:16:23,132 - CMD: fastq-dump -N 2706897 -X 4060344 -O ./pfd_j9vlf9o7/2 --gzip --split-files SRR13349122\n",
      "2022-05-29 16:16:23,133 - CMD: fastq-dump -N 4060345 -X 5413792 -O ./pfd_j9vlf9o7/3 --gzip --split-files SRR13349122\n",
      "2022-05-29 16:16:23,135 - CMD: fastq-dump -N 5413793 -X 6767240 -O ./pfd_j9vlf9o7/4 --gzip --split-files SRR13349122\n",
      "2022-05-29 16:16:23,149 - CMD: fastq-dump -N 6767241 -X 8120688 -O ./pfd_j9vlf9o7/5 --gzip --split-files SRR13349122\n",
      "2022-05-29 16:16:23,167 - CMD: fastq-dump -N 8120689 -X 9474136 -O ./pfd_j9vlf9o7/6 --gzip --split-files SRR13349122\n",
      "2022-05-29 16:16:23,174 - CMD: fastq-dump -N 9474137 -X 10827590 -O ./pfd_j9vlf9o7/7 --gzip --split-files SRR13349122\n",
      "Read 1353448 spots for SRR13349122\n",
      "Written 1353448 spots for SRR13349122\n",
      "Read 1353448 spots for SRR13349122\n",
      "Written 1353448 spots for SRR13349122\n",
      "Read 1353448 spots for SRR13349122\n",
      "Written 1353448 spots for SRR13349122\n",
      "Read 1353448 spots for SRR13349122\n",
      "Written 1353448 spots for SRR13349122\n",
      "Read 1353448 spots for SRR13349122\n",
      "Written 1353448 spots for SRR13349122\n",
      "Read 1353448 spots for SRR13349122\n",
      "Written 1353448 spots for SRR13349122\n",
      "Read 1353454 spots for SRR13349122\n",
      "Written 1353454 spots for SRR13349122\n",
      "Read 1353448 spots for SRR13349122\n",
      "Written 1353448 spots for SRR13349122\n",
      "2022-05-29 16:18:40,138 - SRR ids: ['SRR13349123']\n",
      "2022-05-29 16:18:40,139 - extra args: ['--gzip', '--split-files']\n",
      "2022-05-29 16:18:40,139 - tempdir: ./pfd_640skvg3\n",
      "2022-05-29 16:18:40,139 - CMD: sra-stat --meta --quick SRR13349123\n",
      "2022-05-29 16:18:42,646 - SRR13349123 spots: 11165256\n",
      "2022-05-29 16:18:42,646 - blocks: [[1, 1395657], [1395658, 2791314], [2791315, 4186971], [4186972, 5582628], [5582629, 6978285], [6978286, 8373942], [8373943, 9769599], [9769600, 11165256]]\n",
      "2022-05-29 16:18:42,646 - CMD: fastq-dump -N 1 -X 1395657 -O ./pfd_640skvg3/0 --gzip --split-files SRR13349123\n",
      "2022-05-29 16:18:42,648 - CMD: fastq-dump -N 1395658 -X 2791314 -O ./pfd_640skvg3/1 --gzip --split-files SRR13349123\n",
      "2022-05-29 16:18:42,649 - CMD: fastq-dump -N 2791315 -X 4186971 -O ./pfd_640skvg3/2 --gzip --split-files SRR13349123\n",
      "2022-05-29 16:18:42,651 - CMD: fastq-dump -N 4186972 -X 5582628 -O ./pfd_640skvg3/3 --gzip --split-files SRR13349123\n",
      "2022-05-29 16:18:42,652 - CMD: fastq-dump -N 5582629 -X 6978285 -O ./pfd_640skvg3/4 --gzip --split-files SRR13349123\n",
      "2022-05-29 16:18:42,665 - CMD: fastq-dump -N 6978286 -X 8373942 -O ./pfd_640skvg3/5 --gzip --split-files SRR13349123\n",
      "2022-05-29 16:18:42,685 - CMD: fastq-dump -N 8373943 -X 9769599 -O ./pfd_640skvg3/6 --gzip --split-files SRR13349123\n",
      "2022-05-29 16:18:42,692 - CMD: fastq-dump -N 9769600 -X 11165256 -O ./pfd_640skvg3/7 --gzip --split-files SRR13349123\n",
      "Read 1395657 spots for SRR13349123\n",
      "Written 1395657 spots for SRR13349123\n",
      "Read 1395657 spots for SRR13349123\n",
      "Written 1395657 spots for SRR13349123\n",
      "Read 1395657 spots for SRR13349123\n",
      "Written 1395657 spots for SRR13349123\n",
      "Read 1395657 spots for SRR13349123\n",
      "Written 1395657 spots for SRR13349123\n",
      "Read 1395657 spots for SRR13349123\n",
      "Written 1395657 spots for SRR13349123\n",
      "Read 1395657 spots for SRR13349123\n",
      "Written 1395657 spots for SRR13349123\n",
      "Read 1395657 spots for SRR13349123\n",
      "Written 1395657 spots for SRR13349123\n",
      "Read 1395657 spots for SRR13349123\n",
      "Written 1395657 spots for SRR13349123\n",
      "2022-05-29 16:20:58,772 - SRR ids: ['SRR13349124']\n",
      "2022-05-29 16:20:58,772 - extra args: ['--gzip', '--split-files']\n",
      "2022-05-29 16:20:58,772 - tempdir: ./pfd__prtk4oz\n",
      "2022-05-29 16:20:58,772 - CMD: sra-stat --meta --quick SRR13349124\n",
      "2022-05-29 16:21:01,820 - SRR13349124 spots: 10727273\n",
      "2022-05-29 16:21:01,821 - blocks: [[1, 1340909], [1340910, 2681818], [2681819, 4022727], [4022728, 5363636], [5363637, 6704545], [6704546, 8045454], [8045455, 9386363], [9386364, 10727273]]\n",
      "2022-05-29 16:21:01,821 - CMD: fastq-dump -N 1 -X 1340909 -O ./pfd__prtk4oz/0 --gzip --split-files SRR13349124\n",
      "2022-05-29 16:21:01,822 - CMD: fastq-dump -N 1340910 -X 2681818 -O ./pfd__prtk4oz/1 --gzip --split-files SRR13349124\n",
      "2022-05-29 16:21:01,824 - CMD: fastq-dump -N 2681819 -X 4022727 -O ./pfd__prtk4oz/2 --gzip --split-files SRR13349124\n",
      "2022-05-29 16:21:01,825 - CMD: fastq-dump -N 4022728 -X 5363636 -O ./pfd__prtk4oz/3 --gzip --split-files SRR13349124\n",
      "2022-05-29 16:21:01,827 - CMD: fastq-dump -N 5363637 -X 6704545 -O ./pfd__prtk4oz/4 --gzip --split-files SRR13349124\n",
      "2022-05-29 16:21:01,853 - CMD: fastq-dump -N 6704546 -X 8045454 -O ./pfd__prtk4oz/5 --gzip --split-files SRR13349124\n",
      "2022-05-29 16:21:01,858 - CMD: fastq-dump -N 8045455 -X 9386363 -O ./pfd__prtk4oz/6 --gzip --split-files SRR13349124\n",
      "2022-05-29 16:21:01,864 - CMD: fastq-dump -N 9386364 -X 10727273 -O ./pfd__prtk4oz/7 --gzip --split-files SRR13349124\n",
      "Read 1340909 spots for SRR13349124\n",
      "Written 1340909 spots for SRR13349124\n",
      "Read 1340909 spots for SRR13349124\n",
      "Written 1340909 spots for SRR13349124\n",
      "Read 1340909 spots for SRR13349124\n",
      "Written 1340909 spots for SRR13349124\n",
      "Read 1340909 spots for SRR13349124\n",
      "Written 1340909 spots for SRR13349124\n",
      "Read 1340910 spots for SRR13349124\n",
      "Written 1340910 spots for SRR13349124\n",
      "Read 1340909 spots for SRR13349124\n",
      "Written 1340909 spots for SRR13349124\n",
      "Read 1340909 spots for SRR13349124\n",
      "Written 1340909 spots for SRR13349124\n",
      "Read 1340909 spots for SRR13349124\n",
      "Written 1340909 spots for SRR13349124\n",
      "2022-05-29 16:23:17,132 - SRR ids: ['SRR13349125']\n",
      "2022-05-29 16:23:17,132 - extra args: ['--gzip', '--split-files']\n",
      "2022-05-29 16:23:17,132 - tempdir: ./pfd_3_xy62tf\n",
      "2022-05-29 16:23:17,133 - CMD: sra-stat --meta --quick SRR13349125\n",
      "2022-05-29 16:23:19,737 - SRR13349125 spots: 10992686\n",
      "2022-05-29 16:23:19,737 - blocks: [[1, 1374085], [1374086, 2748170], [2748171, 4122255], [4122256, 5496340], [5496341, 6870425], [6870426, 8244510], [8244511, 9618595], [9618596, 10992686]]\n",
      "2022-05-29 16:23:19,737 - CMD: fastq-dump -N 1 -X 1374085 -O ./pfd_3_xy62tf/0 --gzip --split-files SRR13349125\n",
      "2022-05-29 16:23:19,738 - CMD: fastq-dump -N 1374086 -X 2748170 -O ./pfd_3_xy62tf/1 --gzip --split-files SRR13349125\n",
      "2022-05-29 16:23:19,740 - CMD: fastq-dump -N 2748171 -X 4122255 -O ./pfd_3_xy62tf/2 --gzip --split-files SRR13349125\n",
      "2022-05-29 16:23:19,742 - CMD: fastq-dump -N 4122256 -X 5496340 -O ./pfd_3_xy62tf/3 --gzip --split-files SRR13349125\n",
      "2022-05-29 16:23:19,744 - CMD: fastq-dump -N 5496341 -X 6870425 -O ./pfd_3_xy62tf/4 --gzip --split-files SRR13349125\n",
      "2022-05-29 16:23:19,765 - CMD: fastq-dump -N 6870426 -X 8244510 -O ./pfd_3_xy62tf/5 --gzip --split-files SRR13349125\n",
      "2022-05-29 16:23:19,772 - CMD: fastq-dump -N 8244511 -X 9618595 -O ./pfd_3_xy62tf/6 --gzip --split-files SRR13349125\n",
      "2022-05-29 16:23:19,781 - CMD: fastq-dump -N 9618596 -X 10992686 -O ./pfd_3_xy62tf/7 --gzip --split-files SRR13349125\n",
      "Read 1374085 spots for SRR13349125\n",
      "Written 1374085 spots for SRR13349125\n",
      "Read 1374085 spots for SRR13349125\n",
      "Written 1374085 spots for SRR13349125\n",
      "Read 1374085 spots for SRR13349125\n",
      "Written 1374085 spots for SRR13349125\n",
      "Read 1374085 spots for SRR13349125\n",
      "Written 1374085 spots for SRR13349125\n",
      "Read 1374085 spots for SRR13349125\n",
      "Written 1374085 spots for SRR13349125\n",
      "Read 1374085 spots for SRR13349125\n",
      "Written 1374085 spots for SRR13349125\n",
      "Read 1374085 spots for SRR13349125\n",
      "Written 1374085 spots for SRR13349125\n",
      "Read 1374091 spots for SRR13349125\n",
      "Written 1374091 spots for SRR13349125\n",
      "2022-05-29 16:25:32,617 - SRR ids: ['SRR13349126']\n",
      "2022-05-29 16:25:32,617 - extra args: ['--gzip', '--split-files']\n",
      "2022-05-29 16:25:32,617 - tempdir: ./pfd_d7q4h82i\n",
      "2022-05-29 16:25:32,617 - CMD: sra-stat --meta --quick SRR13349126\n",
      "2022-05-29 16:25:35,135 - SRR13349126 spots: 12267497\n",
      "2022-05-29 16:25:35,136 - blocks: [[1, 1533437], [1533438, 3066874], [3066875, 4600311], [4600312, 6133748], [6133749, 7667185], [7667186, 9200622], [9200623, 10734059], [10734060, 12267497]]\n",
      "2022-05-29 16:25:35,136 - CMD: fastq-dump -N 1 -X 1533437 -O ./pfd_d7q4h82i/0 --gzip --split-files SRR13349126\n",
      "2022-05-29 16:25:35,137 - CMD: fastq-dump -N 1533438 -X 3066874 -O ./pfd_d7q4h82i/1 --gzip --split-files SRR13349126\n",
      "2022-05-29 16:25:35,139 - CMD: fastq-dump -N 3066875 -X 4600311 -O ./pfd_d7q4h82i/2 --gzip --split-files SRR13349126\n",
      "2022-05-29 16:25:35,140 - CMD: fastq-dump -N 4600312 -X 6133748 -O ./pfd_d7q4h82i/3 --gzip --split-files SRR13349126\n",
      "2022-05-29 16:25:35,142 - CMD: fastq-dump -N 6133749 -X 7667185 -O ./pfd_d7q4h82i/4 --gzip --split-files SRR13349126\n",
      "2022-05-29 16:25:35,161 - CMD: fastq-dump -N 7667186 -X 9200622 -O ./pfd_d7q4h82i/5 --gzip --split-files SRR13349126\n",
      "2022-05-29 16:25:35,170 - CMD: fastq-dump -N 9200623 -X 10734059 -O ./pfd_d7q4h82i/6 --gzip --split-files SRR13349126\n",
      "2022-05-29 16:25:35,173 - CMD: fastq-dump -N 10734060 -X 12267497 -O ./pfd_d7q4h82i/7 --gzip --split-files SRR13349126\n",
      "Read 1533437 spots for SRR13349126\n",
      "Written 1533437 spots for SRR13349126\n",
      "Read 1533437 spots for SRR13349126\n",
      "Written 1533437 spots for SRR13349126\n",
      "Read 1533437 spots for SRR13349126\n",
      "Written 1533437 spots for SRR13349126\n",
      "Read 1533438 spots for SRR13349126\n",
      "Written 1533438 spots for SRR13349126\n",
      "Read 1533437 spots for SRR13349126\n",
      "Written 1533437 spots for SRR13349126\n",
      "Read 1533437 spots for SRR13349126\n",
      "Written 1533437 spots for SRR13349126\n",
      "Read 1533437 spots for SRR13349126\n",
      "Written 1533437 spots for SRR13349126\n",
      "Read 1533437 spots for SRR13349126\n",
      "Written 1533437 spots for SRR13349126\n",
      "2022-05-29 16:28:06,833 - SRR ids: ['SRR13349127']\n",
      "2022-05-29 16:28:06,833 - extra args: ['--gzip', '--split-files']\n",
      "2022-05-29 16:28:06,833 - tempdir: ./pfd_2wekogf3\n",
      "2022-05-29 16:28:06,833 - CMD: sra-stat --meta --quick SRR13349127\n",
      "2022-05-29 16:28:09,480 - SRR13349127 spots: 12563032\n",
      "2022-05-29 16:28:09,481 - blocks: [[1, 1570379], [1570380, 3140758], [3140759, 4711137], [4711138, 6281516], [6281517, 7851895], [7851896, 9422274], [9422275, 10992653], [10992654, 12563032]]\n",
      "2022-05-29 16:28:09,481 - CMD: fastq-dump -N 1 -X 1570379 -O ./pfd_2wekogf3/0 --gzip --split-files SRR13349127\n",
      "2022-05-29 16:28:09,482 - CMD: fastq-dump -N 1570380 -X 3140758 -O ./pfd_2wekogf3/1 --gzip --split-files SRR13349127\n",
      "2022-05-29 16:28:09,484 - CMD: fastq-dump -N 3140759 -X 4711137 -O ./pfd_2wekogf3/2 --gzip --split-files SRR13349127\n",
      "2022-05-29 16:28:09,486 - CMD: fastq-dump -N 4711138 -X 6281516 -O ./pfd_2wekogf3/3 --gzip --split-files SRR13349127\n",
      "2022-05-29 16:28:09,488 - CMD: fastq-dump -N 6281517 -X 7851895 -O ./pfd_2wekogf3/4 --gzip --split-files SRR13349127\n",
      "2022-05-29 16:28:09,505 - CMD: fastq-dump -N 7851896 -X 9422274 -O ./pfd_2wekogf3/5 --gzip --split-files SRR13349127\n",
      "2022-05-29 16:28:09,520 - CMD: fastq-dump -N 9422275 -X 10992653 -O ./pfd_2wekogf3/6 --gzip --split-files SRR13349127\n",
      "2022-05-29 16:28:09,524 - CMD: fastq-dump -N 10992654 -X 12563032 -O ./pfd_2wekogf3/7 --gzip --split-files SRR13349127\n",
      "Read 1570379 spots for SRR13349127\n",
      "Written 1570379 spots for SRR13349127\n",
      "Read 1570379 spots for SRR13349127\n",
      "Written 1570379 spots for SRR13349127\n",
      "Read 1570379 spots for SRR13349127\n",
      "Written 1570379 spots for SRR13349127\n",
      "Read 1570379 spots for SRR13349127\n",
      "Written 1570379 spots for SRR13349127\n",
      "Read 1570379 spots for SRR13349127\n",
      "Written 1570379 spots for SRR13349127\n",
      "Read 1570379 spots for SRR13349127\n",
      "Written 1570379 spots for SRR13349127\n",
      "Read 1570379 spots for SRR13349127\n",
      "Written 1570379 spots for SRR13349127\n",
      "Read 1570379 spots for SRR13349127\n",
      "Written 1570379 spots for SRR13349127\n",
      "2022-05-29 16:30:40,342 - SRR ids: ['SRR13349128']\n",
      "2022-05-29 16:30:40,342 - extra args: ['--gzip', '--split-files']\n",
      "2022-05-29 16:30:40,342 - tempdir: ./pfd_ymy7a6gf\n",
      "2022-05-29 16:30:40,342 - CMD: sra-stat --meta --quick SRR13349128\n",
      "2022-05-29 16:30:43,153 - SRR13349128 spots: 12652387\n",
      "2022-05-29 16:30:43,154 - blocks: [[1, 1581548], [1581549, 3163096], [3163097, 4744644], [4744645, 6326192], [6326193, 7907740], [7907741, 9489288], [9489289, 11070836], [11070837, 12652387]]\n",
      "2022-05-29 16:30:43,154 - CMD: fastq-dump -N 1 -X 1581548 -O ./pfd_ymy7a6gf/0 --gzip --split-files SRR13349128\n",
      "2022-05-29 16:30:43,155 - CMD: fastq-dump -N 1581549 -X 3163096 -O ./pfd_ymy7a6gf/1 --gzip --split-files SRR13349128\n",
      "2022-05-29 16:30:43,157 - CMD: fastq-dump -N 3163097 -X 4744644 -O ./pfd_ymy7a6gf/2 --gzip --split-files SRR13349128\n",
      "2022-05-29 16:30:43,158 - CMD: fastq-dump -N 4744645 -X 6326192 -O ./pfd_ymy7a6gf/3 --gzip --split-files SRR13349128\n",
      "2022-05-29 16:30:43,164 - CMD: fastq-dump -N 6326193 -X 7907740 -O ./pfd_ymy7a6gf/4 --gzip --split-files SRR13349128\n",
      "2022-05-29 16:30:43,181 - CMD: fastq-dump -N 7907741 -X 9489288 -O ./pfd_ymy7a6gf/5 --gzip --split-files SRR13349128\n",
      "2022-05-29 16:30:43,189 - CMD: fastq-dump -N 9489289 -X 11070836 -O ./pfd_ymy7a6gf/6 --gzip --split-files SRR13349128\n",
      "2022-05-29 16:30:43,198 - CMD: fastq-dump -N 11070837 -X 12652387 -O ./pfd_ymy7a6gf/7 --gzip --split-files SRR13349128\n",
      "Read 1581548 spots for SRR13349128\n",
      "Written 1581548 spots for SRR13349128\n",
      "Read 1581548 spots for SRR13349128\n",
      "Written 1581548 spots for SRR13349128\n",
      "Read 1581548 spots for SRR13349128\n",
      "Written 1581548 spots for SRR13349128\n",
      "Read 1581548 spots for SRR13349128\n",
      "Written 1581548 spots for SRR13349128\n",
      "Read 1581548 spots for SRR13349128\n",
      "Written 1581548 spots for SRR13349128\n",
      "Read 1581551 spots for SRR13349128\n",
      "Written 1581551 spots for SRR13349128\n",
      "Read 1581548 spots for SRR13349128\n",
      "Written 1581548 spots for SRR13349128\n",
      "Read 1581548 spots for SRR13349128\n",
      "Written 1581548 spots for SRR13349128\n",
      "2022-05-29 16:33:19,279 - SRR ids: ['SRR13349129']\n",
      "2022-05-29 16:33:19,279 - extra args: ['--gzip', '--split-files']\n",
      "2022-05-29 16:33:19,280 - tempdir: ./pfd_q9l3tjin\n",
      "2022-05-29 16:33:19,280 - CMD: sra-stat --meta --quick SRR13349129\n",
      "2022-05-29 16:33:21,995 - SRR13349129 spots: 12961793\n",
      "2022-05-29 16:33:21,995 - blocks: [[1, 1620224], [1620225, 3240448], [3240449, 4860672], [4860673, 6480896], [6480897, 8101120], [8101121, 9721344], [9721345, 11341568], [11341569, 12961793]]\n",
      "2022-05-29 16:33:21,995 - CMD: fastq-dump -N 1 -X 1620224 -O ./pfd_q9l3tjin/0 --gzip --split-files SRR13349129\n",
      "2022-05-29 16:33:21,997 - CMD: fastq-dump -N 1620225 -X 3240448 -O ./pfd_q9l3tjin/1 --gzip --split-files SRR13349129\n",
      "2022-05-29 16:33:21,998 - CMD: fastq-dump -N 3240449 -X 4860672 -O ./pfd_q9l3tjin/2 --gzip --split-files SRR13349129\n",
      "2022-05-29 16:33:22,000 - CMD: fastq-dump -N 4860673 -X 6480896 -O ./pfd_q9l3tjin/3 --gzip --split-files SRR13349129\n",
      "2022-05-29 16:33:22,003 - CMD: fastq-dump -N 6480897 -X 8101120 -O ./pfd_q9l3tjin/4 --gzip --split-files SRR13349129\n",
      "2022-05-29 16:33:22,025 - CMD: fastq-dump -N 8101121 -X 9721344 -O ./pfd_q9l3tjin/5 --gzip --split-files SRR13349129\n",
      "2022-05-29 16:33:22,034 - CMD: fastq-dump -N 9721345 -X 11341568 -O ./pfd_q9l3tjin/6 --gzip --split-files SRR13349129\n",
      "2022-05-29 16:33:22,040 - CMD: fastq-dump -N 11341569 -X 12961793 -O ./pfd_q9l3tjin/7 --gzip --split-files SRR13349129\n",
      "Read 1620224 spots for SRR13349129\n",
      "Written 1620224 spots for SRR13349129\n",
      "Read 1620224 spots for SRR13349129\n",
      "Written 1620224 spots for SRR13349129\n",
      "Read 1620224 spots for SRR13349129\n",
      "Written 1620224 spots for SRR13349129\n",
      "Read 1620224 spots for SRR13349129\n",
      "Written 1620224 spots for SRR13349129\n",
      "Read 1620224 spots for SRR13349129\n",
      "Written 1620224 spots for SRR13349129\n",
      "Read 1620224 spots for SRR13349129\n",
      "Written 1620224 spots for SRR13349129\n",
      "Read 1620224 spots for SRR13349129\n",
      "Written 1620224 spots for SRR13349129\n",
      "Read 1620225 spots for SRR13349129\n",
      "Written 1620225 spots for SRR13349129\n",
      "2022-05-29 16:35:55,201 - SRR ids: ['SRR13349130']\n",
      "2022-05-29 16:35:55,201 - extra args: ['--gzip', '--split-files']\n",
      "2022-05-29 16:35:55,201 - tempdir: ./pfd_n8w_a254\n",
      "2022-05-29 16:35:55,201 - CMD: sra-stat --meta --quick SRR13349130\n",
      "2022-05-29 16:35:57,899 - SRR13349130 spots: 10083015\n",
      "2022-05-29 16:35:57,899 - blocks: [[1, 1260376], [1260377, 2520752], [2520753, 3781128], [3781129, 5041504], [5041505, 6301880], [6301881, 7562256], [7562257, 8822632], [8822633, 10083015]]\n",
      "2022-05-29 16:35:57,899 - CMD: fastq-dump -N 1 -X 1260376 -O ./pfd_n8w_a254/0 --gzip --split-files SRR13349130\n",
      "2022-05-29 16:35:57,901 - CMD: fastq-dump -N 1260377 -X 2520752 -O ./pfd_n8w_a254/1 --gzip --split-files SRR13349130\n",
      "2022-05-29 16:35:57,902 - CMD: fastq-dump -N 2520753 -X 3781128 -O ./pfd_n8w_a254/2 --gzip --split-files SRR13349130\n",
      "2022-05-29 16:35:57,904 - CMD: fastq-dump -N 3781129 -X 5041504 -O ./pfd_n8w_a254/3 --gzip --split-files SRR13349130\n",
      "2022-05-29 16:35:57,906 - CMD: fastq-dump -N 5041505 -X 6301880 -O ./pfd_n8w_a254/4 --gzip --split-files SRR13349130\n",
      "2022-05-29 16:35:57,929 - CMD: fastq-dump -N 6301881 -X 7562256 -O ./pfd_n8w_a254/5 --gzip --split-files SRR13349130\n",
      "2022-05-29 16:35:57,941 - CMD: fastq-dump -N 7562257 -X 8822632 -O ./pfd_n8w_a254/6 --gzip --split-files SRR13349130\n",
      "2022-05-29 16:35:57,945 - CMD: fastq-dump -N 8822633 -X 10083015 -O ./pfd_n8w_a254/7 --gzip --split-files SRR13349130\n",
      "Read 1260376 spots for SRR13349130\n",
      "Written 1260376 spots for SRR13349130\n",
      "Read 1260376 spots for SRR13349130\n",
      "Written 1260376 spots for SRR13349130\n",
      "Read 1260376 spots for SRR13349130\n",
      "Written 1260376 spots for SRR13349130\n",
      "Read 1260383 spots for SRR13349130\n",
      "Written 1260383 spots for SRR13349130\n",
      "Read 1260376 spots for SRR13349130\n",
      "Written 1260376 spots for SRR13349130\n",
      "Read 1260376 spots for SRR13349130\n",
      "Written 1260376 spots for SRR13349130\n",
      "Read 1260376 spots for SRR13349130\n",
      "Written 1260376 spots for SRR13349130\n",
      "Read 1260376 spots for SRR13349130\n",
      "Written 1260376 spots for SRR13349130\n",
      "2022-05-29 16:38:02,733 - SRR ids: ['SRR13349131']\n",
      "2022-05-29 16:38:02,733 - extra args: ['--gzip', '--split-files']\n",
      "2022-05-29 16:38:02,733 - tempdir: ./pfd_jb95867k\n",
      "2022-05-29 16:38:02,734 - CMD: sra-stat --meta --quick SRR13349131\n",
      "2022-05-29 16:38:05,499 - SRR13349131 spots: 10491160\n",
      "2022-05-29 16:38:05,499 - blocks: [[1, 1311395], [1311396, 2622790], [2622791, 3934185], [3934186, 5245580], [5245581, 6556975], [6556976, 7868370], [7868371, 9179765], [9179766, 10491160]]\n",
      "2022-05-29 16:38:05,499 - CMD: fastq-dump -N 1 -X 1311395 -O ./pfd_jb95867k/0 --gzip --split-files SRR13349131\n",
      "2022-05-29 16:38:05,500 - CMD: fastq-dump -N 1311396 -X 2622790 -O ./pfd_jb95867k/1 --gzip --split-files SRR13349131\n",
      "2022-05-29 16:38:05,502 - CMD: fastq-dump -N 2622791 -X 3934185 -O ./pfd_jb95867k/2 --gzip --split-files SRR13349131\n",
      "2022-05-29 16:38:05,504 - CMD: fastq-dump -N 3934186 -X 5245580 -O ./pfd_jb95867k/3 --gzip --split-files SRR13349131\n",
      "2022-05-29 16:38:05,506 - CMD: fastq-dump -N 5245581 -X 6556975 -O ./pfd_jb95867k/4 --gzip --split-files SRR13349131\n",
      "2022-05-29 16:38:05,521 - CMD: fastq-dump -N 6556976 -X 7868370 -O ./pfd_jb95867k/5 --gzip --split-files SRR13349131\n",
      "2022-05-29 16:38:05,536 - CMD: fastq-dump -N 7868371 -X 9179765 -O ./pfd_jb95867k/6 --gzip --split-files SRR13349131\n",
      "2022-05-29 16:38:05,538 - CMD: fastq-dump -N 9179766 -X 10491160 -O ./pfd_jb95867k/7 --gzip --split-files SRR13349131\n",
      "Read 1311395 spots for SRR13349131\n",
      "Written 1311395 spots for SRR13349131\n",
      "Read 1311395 spots for SRR13349131\n",
      "Written 1311395 spots for SRR13349131\n",
      "Read 1311395 spots for SRR13349131\n",
      "Written 1311395 spots for SRR13349131\n",
      "Read 1311395 spots for SRR13349131\n",
      "Written 1311395 spots for SRR13349131\n",
      "Read 1311395 spots for SRR13349131\n",
      "Written 1311395 spots for SRR13349131\n",
      "Read 1311395 spots for SRR13349131\n",
      "Written 1311395 spots for SRR13349131\n",
      "Read 1311395 spots for SRR13349131\n",
      "Written 1311395 spots for SRR13349131\n",
      "Read 1311395 spots for SRR13349131\n",
      "Written 1311395 spots for SRR13349131\n",
      "2022-05-29 16:40:10,938 - SRR ids: ['SRR13349132']\n",
      "2022-05-29 16:40:10,938 - extra args: ['--gzip', '--split-files']\n",
      "2022-05-29 16:40:10,938 - tempdir: ./pfd_9w0s252f\n",
      "2022-05-29 16:40:10,938 - CMD: sra-stat --meta --quick SRR13349132\n",
      "2022-05-29 16:40:15,168 - SRR13349132 spots: 11341357\n",
      "2022-05-29 16:40:15,168 - blocks: [[1, 1417669], [1417670, 2835338], [2835339, 4253007], [4253008, 5670676], [5670677, 7088345], [7088346, 8506014], [8506015, 9923683], [9923684, 11341357]]\n",
      "2022-05-29 16:40:15,168 - CMD: fastq-dump -N 1 -X 1417669 -O ./pfd_9w0s252f/0 --gzip --split-files SRR13349132\n",
      "2022-05-29 16:40:15,170 - CMD: fastq-dump -N 1417670 -X 2835338 -O ./pfd_9w0s252f/1 --gzip --split-files SRR13349132\n",
      "2022-05-29 16:40:15,171 - CMD: fastq-dump -N 2835339 -X 4253007 -O ./pfd_9w0s252f/2 --gzip --split-files SRR13349132\n",
      "2022-05-29 16:40:15,173 - CMD: fastq-dump -N 4253008 -X 5670676 -O ./pfd_9w0s252f/3 --gzip --split-files SRR13349132\n",
      "2022-05-29 16:40:15,175 - CMD: fastq-dump -N 5670677 -X 7088345 -O ./pfd_9w0s252f/4 --gzip --split-files SRR13349132\n",
      "2022-05-29 16:40:15,189 - CMD: fastq-dump -N 7088346 -X 8506014 -O ./pfd_9w0s252f/5 --gzip --split-files SRR13349132\n",
      "2022-05-29 16:40:15,205 - CMD: fastq-dump -N 8506015 -X 9923683 -O ./pfd_9w0s252f/6 --gzip --split-files SRR13349132\n",
      "2022-05-29 16:40:15,211 - CMD: fastq-dump -N 9923684 -X 11341357 -O ./pfd_9w0s252f/7 --gzip --split-files SRR13349132\n",
      "Read 1417669 spots for SRR13349132\n",
      "Written 1417669 spots for SRR13349132\n",
      "Read 1417669 spots for SRR13349132\n",
      "Written 1417669 spots for SRR13349132\n",
      "Read 1417669 spots for SRR13349132\n",
      "Written 1417669 spots for SRR13349132\n",
      "Read 1417669 spots for SRR13349132\n",
      "Written 1417669 spots for SRR13349132\n",
      "Read 1417669 spots for SRR13349132\n",
      "Written 1417669 spots for SRR13349132\n",
      "Read 1417674 spots for SRR13349132\n",
      "Written 1417674 spots for SRR13349132\n",
      "Read 1417669 spots for SRR13349132\n",
      "Written 1417669 spots for SRR13349132\n",
      "Read 1417669 spots for SRR13349132\n",
      "Written 1417669 spots for SRR13349132\n",
      "2022-05-29 16:42:37,063 - SRR ids: ['SRR13349133']\n",
      "2022-05-29 16:42:37,064 - extra args: ['--gzip', '--split-files']\n",
      "2022-05-29 16:42:37,064 - tempdir: ./pfd_df4tbe2c\n",
      "2022-05-29 16:42:37,064 - CMD: sra-stat --meta --quick SRR13349133\n",
      "2022-05-29 16:42:40,121 - SRR13349133 spots: 11603881\n",
      "2022-05-29 16:42:40,122 - blocks: [[1, 1450485], [1450486, 2900970], [2900971, 4351455], [4351456, 5801940], [5801941, 7252425], [7252426, 8702910], [8702911, 10153395], [10153396, 11603881]]\n",
      "2022-05-29 16:42:40,122 - CMD: fastq-dump -N 1 -X 1450485 -O ./pfd_df4tbe2c/0 --gzip --split-files SRR13349133\n",
      "2022-05-29 16:42:40,123 - CMD: fastq-dump -N 1450486 -X 2900970 -O ./pfd_df4tbe2c/1 --gzip --split-files SRR13349133\n",
      "2022-05-29 16:42:40,125 - CMD: fastq-dump -N 2900971 -X 4351455 -O ./pfd_df4tbe2c/2 --gzip --split-files SRR13349133\n",
      "2022-05-29 16:42:40,126 - CMD: fastq-dump -N 4351456 -X 5801940 -O ./pfd_df4tbe2c/3 --gzip --split-files SRR13349133\n",
      "2022-05-29 16:42:40,128 - CMD: fastq-dump -N 5801941 -X 7252425 -O ./pfd_df4tbe2c/4 --gzip --split-files SRR13349133\n",
      "2022-05-29 16:42:40,145 - CMD: fastq-dump -N 7252426 -X 8702910 -O ./pfd_df4tbe2c/5 --gzip --split-files SRR13349133\n",
      "2022-05-29 16:42:40,161 - CMD: fastq-dump -N 8702911 -X 10153395 -O ./pfd_df4tbe2c/6 --gzip --split-files SRR13349133\n",
      "2022-05-29 16:42:40,168 - CMD: fastq-dump -N 10153396 -X 11603881 -O ./pfd_df4tbe2c/7 --gzip --split-files SRR13349133\n",
      "Read 1450485 spots for SRR13349133\n",
      "Written 1450485 spots for SRR13349133\n",
      "Read 1450485 spots for SRR13349133\n",
      "Written 1450485 spots for SRR13349133\n",
      "Read 1450485 spots for SRR13349133\n",
      "Written 1450485 spots for SRR13349133\n",
      "Read 1450485 spots for SRR13349133\n",
      "Written 1450485 spots for SRR13349133\n",
      "Read 1450485 spots for SRR13349133\n",
      "Written 1450485 spots for SRR13349133\n",
      "Read 1450485 spots for SRR13349133\n",
      "Written 1450485 spots for SRR13349133\n",
      "Read 1450485 spots for SRR13349133\n",
      "Written 1450485 spots for SRR13349133\n",
      "Read 1450486 spots for SRR13349133\n",
      "Written 1450486 spots for SRR13349133\n",
      "16:45:00\n"
     ]
    }
   ],
   "source": [
    "!cat data/raw_fastq/list_of_accesionIDS.txt |xargs -I {} parallel-fastq-dump -O data/raw_fastq/ --tmpdir . --threads 8 --gzip --split-files --sra-id {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP 4: Copy reference transcriptome files that will be used by Salmon using E-Direct\n",
    "\n",
    "Salmon is a tool that aligns RNA-Seq reads to a set of transcripts rather than the entire genome.\n",
    "\n",
    "So we will need a transcriptome reference.\n",
    "\n",
    "To get one, we can search through the NCBI assembly database, find an assembly, and download transcriptome reference files from that assembly using FTP links.\n",
    "\n",
    "For instance, we will use the <a href='https://www.ncbi.nlm.nih.gov/assembly/GCF_001632805.1'>ASM163280v1</a> refseq assembly, found by searching through the NCBI assembly database. The FTP links can be accessed through the website in various ways, one way is to click the 'FTP directory for RefSeq assembly' link, found under 'Access the data', section.\n",
    "\n",
    "Alternatively, this process can be done through the NCBI command line set of tools called 'Entrez Direct' (EDirect).\n",
    "\n",
    "The bottom lines of code show how FTP links for specific files in a given assembly can be performed using EDirect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1436k  100 1436k    0     0   837k      0  0:00:01  0:00:01 --:--:--  837k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  329k  100  329k    0     0   241k      0  0:00:01  0:00:01 --:--:--  241k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  222k  100  222k    0     0   171k      0  0:00:01  0:00:01 --:--:--  171k\n",
      "16:45:11\n"
     ]
    }
   ],
   "source": [
    "#parse for the ftp link and download the genome reference fasta file\n",
    "\n",
    "!esearch -db assembly -query GCF_001632805.1 | efetch -format docsum \\\n",
    "| xtract -pattern DocumentSummary -element FtpPath_RefSeq \\\n",
    "| awk -F\"/\" '{print \"curl -o data/reference/\"$NF\"_genomic.fna.gz \" $0\"/\"$NF\"_genomic.fna.gz\"}' \\\n",
    "| bash\n",
    "\n",
    "#parse for the ftp link and download the gtf reference fasta file\n",
    "\n",
    "!esearch -db assembly -query GCF_001632805.1 | efetch -format docsum \\\n",
    "| xtract -pattern DocumentSummary -element FtpPath_RefSeq \\\n",
    "| awk -F\"/\" '{print \"curl -o data/reference/\"$NF\"_genomic.gff.gz \" $0\"/\"$NF\"_genomic.gff.gz\"}' \\\n",
    "| bash\n",
    "\n",
    "# parse for the ftp link and download the feature-table reference file \n",
    "# (for later use for merging readcounts with gene names in R code).\n",
    "\n",
    "!esearch -db assembly -query GCF_001632805.1 | efetch -format docsum \\\n",
    "| xtract -pattern DocumentSummary -element FtpPath_RefSeq \\\n",
    "| awk -F\"/\" '{print \"curl -o data/reference/\"$NF\"_feature_table.txt.gz \" $0\"/\"$NF\"_feature_table.txt.gz\"}' \\\n",
    "| bash\n",
    "\n",
    "\n",
    "#unzip the compresseed fasta files\n",
    "\n",
    "!gzip -d data/reference/*.gz --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can use gffread to create a transcriptome reference file using the gtf and genome files we downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:45:11\n"
     ]
    }
   ],
   "source": [
    "!gffread -w data/reference/GCF_001632805.1_transcriptome_reference.fa -g data/reference/GCF_001632805.1_ASM163280v1_genomic.fna data/reference/GCF_001632805.1_ASM163280v1_genomic.gff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also include the genome at the end of the reference file, for the purpose of creating a 'decoy-aware' transcriptome file, more information for which can be found in the Salmon documentation.\n",
    "\n",
    "Accordingly, also for purpose of decoy-aware indexing, we will also create a 'decoy file', which salmon needs to point to the genome sequence in our transcriptome reference file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:45:11\n"
     ]
    }
   ],
   "source": [
    "!cat data/reference/GCF_001632805.1_transcriptome_reference.fa <(echo) data/reference/GCF_001632805.1_ASM163280v1_genomic.fna > data/reference/GCF_001632805.1_transcriptome_reference_w_decoy.fa\n",
    "!echo \"NZ_CP007220.1\" > data/reference/decoys.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5: Copy data file for Trimmomatic\n",
    "\n",
    "One of trimmomatics functions is to trim sequence machine specific adapter sequences. These are usually within the trimmomatic installation directory in a folder called adapters.\n",
    "\n",
    "Directories of packages within conda installations can be confusing, so in the case of using conda with trimmomatic, it may be easier to simply download or create a file with the relevant adapter sequencecs and store it in an easy to find directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    95  100    95    0     0    341      0 --:--:-- --:--:-- --:--:--   341\n",
      ">PrefixPE/1\n",
      "TACACTCTTTCCCTACACGACGCTCTTCCGATCT\n",
      ">PrefixPE/2\n",
      "GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT\n",
      "\n",
      "16:45:12\n"
     ]
    }
   ],
   "source": [
    "!curl https://storage.googleapis.com/me-inbre-rnaseq-pipelinev2/config/TruSeq3-PE.fa --output TruSeq3-PE.fa\n",
    "!head TruSeq3-PE.fa "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 6: Run Trimmomatic\n",
    "Trimmomatic will trim off any adapter sequences or low quality sequence it detects in the FASTQ files.\n",
    "\n",
    "For simplicity sake, it is possible to use our original list of run IDs to run trimmomatic on all of our fastq files in one line of code.\n",
    "\n",
    "The below code may take approximately 35 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 2 data/raw_fastq/SRR13349122_1.fastq.gz data/raw_fastq/SRR13349122_2.fastq.gz data/trimmed/SRR13349122_1_trimmed.fastq.gz data/trimmed/SRR13349122_2_trimmed.fastq.gz data/trimmed/SRR13349122_1_trimmed_unpaired.fastq.gz data/trimmed/SRR13349122_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 10827590 Both Surviving: 10810267 (99.84%) Forward Only Surviving: 17297 (0.16%) Reverse Only Surviving: 0 (0.00%) Dropped: 26 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 2 data/raw_fastq/SRR13349123_1.fastq.gz data/raw_fastq/SRR13349123_2.fastq.gz data/trimmed/SRR13349123_1_trimmed.fastq.gz data/trimmed/SRR13349123_2_trimmed.fastq.gz data/trimmed/SRR13349123_1_trimmed_unpaired.fastq.gz data/trimmed/SRR13349123_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 11165256 Both Surviving: 11096258 (99.38%) Forward Only Surviving: 68966 (0.62%) Reverse Only Surviving: 0 (0.00%) Dropped: 32 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 2 data/raw_fastq/SRR13349124_1.fastq.gz data/raw_fastq/SRR13349124_2.fastq.gz data/trimmed/SRR13349124_1_trimmed.fastq.gz data/trimmed/SRR13349124_2_trimmed.fastq.gz data/trimmed/SRR13349124_1_trimmed_unpaired.fastq.gz data/trimmed/SRR13349124_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 10727273 Both Surviving: 10710165 (99.84%) Forward Only Surviving: 17076 (0.16%) Reverse Only Surviving: 0 (0.00%) Dropped: 32 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 2 data/raw_fastq/SRR13349125_1.fastq.gz data/raw_fastq/SRR13349125_2.fastq.gz data/trimmed/SRR13349125_1_trimmed.fastq.gz data/trimmed/SRR13349125_2_trimmed.fastq.gz data/trimmed/SRR13349125_1_trimmed_unpaired.fastq.gz data/trimmed/SRR13349125_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 10992686 Both Surviving: 10924466 (99.38%) Forward Only Surviving: 68182 (0.62%) Reverse Only Surviving: 0 (0.00%) Dropped: 38 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 2 data/raw_fastq/SRR13349126_1.fastq.gz data/raw_fastq/SRR13349126_2.fastq.gz data/trimmed/SRR13349126_1_trimmed.fastq.gz data/trimmed/SRR13349126_2_trimmed.fastq.gz data/trimmed/SRR13349126_1_trimmed_unpaired.fastq.gz data/trimmed/SRR13349126_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 12267497 Both Surviving: 12248005 (99.84%) Forward Only Surviving: 19411 (0.16%) Reverse Only Surviving: 0 (0.00%) Dropped: 81 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 2 data/raw_fastq/SRR13349127_1.fastq.gz data/raw_fastq/SRR13349127_2.fastq.gz data/trimmed/SRR13349127_1_trimmed.fastq.gz data/trimmed/SRR13349127_2_trimmed.fastq.gz data/trimmed/SRR13349127_1_trimmed_unpaired.fastq.gz data/trimmed/SRR13349127_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 12563032 Both Surviving: 12485561 (99.38%) Forward Only Surviving: 77386 (0.62%) Reverse Only Surviving: 0 (0.00%) Dropped: 85 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 2 data/raw_fastq/SRR13349128_1.fastq.gz data/raw_fastq/SRR13349128_2.fastq.gz data/trimmed/SRR13349128_1_trimmed.fastq.gz data/trimmed/SRR13349128_2_trimmed.fastq.gz data/trimmed/SRR13349128_1_trimmed_unpaired.fastq.gz data/trimmed/SRR13349128_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 12652387 Both Surviving: 12631972 (99.84%) Forward Only Surviving: 20327 (0.16%) Reverse Only Surviving: 0 (0.00%) Dropped: 88 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 2 data/raw_fastq/SRR13349129_1.fastq.gz data/raw_fastq/SRR13349129_2.fastq.gz data/trimmed/SRR13349129_1_trimmed.fastq.gz data/trimmed/SRR13349129_2_trimmed.fastq.gz data/trimmed/SRR13349129_1_trimmed_unpaired.fastq.gz data/trimmed/SRR13349129_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 12961793 Both Surviving: 12881935 (99.38%) Forward Only Surviving: 79783 (0.62%) Reverse Only Surviving: 0 (0.00%) Dropped: 75 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 2 data/raw_fastq/SRR13349130_1.fastq.gz data/raw_fastq/SRR13349130_2.fastq.gz data/trimmed/SRR13349130_1_trimmed.fastq.gz data/trimmed/SRR13349130_2_trimmed.fastq.gz data/trimmed/SRR13349130_1_trimmed_unpaired.fastq.gz data/trimmed/SRR13349130_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 10083015 Both Surviving: 10067073 (99.84%) Forward Only Surviving: 15920 (0.16%) Reverse Only Surviving: 0 (0.00%) Dropped: 22 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 2 data/raw_fastq/SRR13349131_1.fastq.gz data/raw_fastq/SRR13349131_2.fastq.gz data/trimmed/SRR13349131_1_trimmed.fastq.gz data/trimmed/SRR13349131_2_trimmed.fastq.gz data/trimmed/SRR13349131_1_trimmed_unpaired.fastq.gz data/trimmed/SRR13349131_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 10491160 Both Surviving: 10427189 (99.39%) Forward Only Surviving: 63929 (0.61%) Reverse Only Surviving: 0 (0.00%) Dropped: 42 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 2 data/raw_fastq/SRR13349132_1.fastq.gz data/raw_fastq/SRR13349132_2.fastq.gz data/trimmed/SRR13349132_1_trimmed.fastq.gz data/trimmed/SRR13349132_2_trimmed.fastq.gz data/trimmed/SRR13349132_1_trimmed_unpaired.fastq.gz data/trimmed/SRR13349132_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 11341357 Both Surviving: 11323093 (99.84%) Forward Only Surviving: 18224 (0.16%) Reverse Only Surviving: 0 (0.00%) Dropped: 40 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 2 data/raw_fastq/SRR13349133_1.fastq.gz data/raw_fastq/SRR13349133_2.fastq.gz data/trimmed/SRR13349133_1_trimmed.fastq.gz data/trimmed/SRR13349133_2_trimmed.fastq.gz data/trimmed/SRR13349133_1_trimmed_unpaired.fastq.gz data/trimmed/SRR13349133_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 11603881 Both Surviving: 11531393 (99.38%) Forward Only Surviving: 72435 (0.62%) Reverse Only Surviving: 0 (0.00%) Dropped: 53 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "17:19:30\n"
     ]
    }
   ],
   "source": [
    "!cat data/raw_fastq/list_of_accesionIDS.txt | xargs -I {} trimmomatic PE -threads 2 'data/raw_fastq/{}_1.fastq.gz' 'data/raw_fastq/{}_2.fastq.gz' 'data/trimmed/{}_1_trimmed.fastq.gz' 'data/trimmed/{}_2_trimmed.fastq.gz' 'data/trimmed/{}_1_trimmed_unpaired.fastq.gz'  'data/trimmed/{}_2_trimmed_unpaired.fastq.gz' ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 7: Run FastQC\n",
    "FastQC is an invaluable tool that allows you to evaluate whether there are problems with a set of reads. For example, it will provide a report of whether there is any bias in the sequence composition of the reads.\n",
    "\n",
    "If you notice the results of the trimming, you may have noted the sequences in the reverse reads were few, and largely unpaired. This may be an artifact from how the original sequencing process. This is okay, we can proceed from here simply using the forward reads.\n",
    "\n",
    "The below code may take around 10 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Started analysis of SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Started analysis of SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Started analysis of SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Started analysis of SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 100% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Started analysis of SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Started analysis of SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Started analysis of SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Started analysis of SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Started analysis of SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Started analysis of SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Started analysis of SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349133_1_trimmed.fastq.gz\n",
      "17:29:36\n"
     ]
    }
   ],
   "source": [
    "!cat data/raw_fastq/list_of_accesionIDS.txt | xargs -I {} fastqc \"data/trimmed/{}_1_trimmed.fastq.gz\" -o data/fastqc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 8: Run MultiQC\n",
    "MultiQC reads in the FastQC reports and generate a compiled report for all the analyzed FASTQ files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[34m/\u001b[0m\u001b[32m/\u001b[0m\u001b[31m/\u001b[0m \u001b]8;id=299124;https://multiqc.info\u001b\\\u001b[1mMultiQC\u001b[0m\u001b]8;;\u001b\\  \u001b[2m| v1.12\u001b[0m\n",
      "\n",
      "\u001b[34m|           multiqc\u001b[0m | Search path : /home/jupyter/rnaseq-myco-notebook/data/fastqc\n",
      "\u001b[2K\u001b[34m|\u001b[0m         \u001b[34msearching\u001b[0m | \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m32/32\u001b[0m  mmed_1_fastqc.html\u001b[0m.html\u001b[0m\n",
      "\u001b[?25h\u001b[34m|            fastqc\u001b[0m | Found 16 reports\n",
      "\u001b[34m|           multiqc\u001b[0m | Compressing plot data\n",
      "\u001b[34m|           multiqc\u001b[0m | \u001b[33mDeleting    : multiqc_report.html   (-f was specified)\u001b[0m\n",
      "\u001b[34m|           multiqc\u001b[0m | \u001b[33mDeleting    : multiqc_data   (-f was specified)\u001b[0m\n",
      "\u001b[34m|           multiqc\u001b[0m | Report      : multiqc_report.html\n",
      "\u001b[34m|           multiqc\u001b[0m | Data        : multiqc_data\n",
      "\u001b[34m|           multiqc\u001b[0m | MultiQC complete\n",
      "17:29:43\n"
     ]
    }
   ],
   "source": [
    "!multiqc -f data/fastqc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 9: Index the Transcriptome so that Trimmed Reads Can Be Mapped Using Salmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version Info: ### PLEASE UPGRADE SALMON ###\n",
      "### A newer version of salmon with important bug fixes and improvements is available. ####\n",
      "###\n",
      "The newest version, available at https://github.com/COMBINE-lab/salmon/releases\n",
      "contains new features, improvements, and bug fixes; please upgrade at your\n",
      "earliest convenience.\n",
      "###\n",
      "Sign up for the salmon mailing list to hear about new versions, features and updates at:\n",
      "https://oceangenomics.com/subscribe\n",
      "[2022-05-29 17:29:44.474] [jLog] [info] building index\n",
      "out : data/reference/transcriptome_index\n",
      "\u001b[00m[2022-05-29 17:29:44.474] [puff::index::jointLog] [info] Running fixFasta\n",
      "\u001b[00m\n",
      "[Step 1 of 4] : counting k-mers\n",
      "\n",
      "\u001b[35m[2022-05-29 17:29:44.694] [puff::index::jointLog] [warning] There were 1 transcripts that would need to be removed to avoid duplicates.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:29:44.694] [puff::index::jointLog] [info] Replaced 0 non-ATCG nucleotides\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:29:44.694] [puff::index::jointLog] [info] Clipped poly-A tails from 0 transcripts\n",
      "\u001b[00mwrote 4907 cleaned references\n",
      "\u001b[00m[2022-05-29 17:29:44.713] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:29:44.806] [puff::index::jointLog] [info] ntHll estimated 4966944 distinct k-mers, setting filter size to 2^27\n",
      "\u001b[00mThreads = 8\n",
      "Vertex length = 31\n",
      "Hash functions = 5\n",
      "Filter size = 134217728\n",
      "Capacity = 2\n",
      "Files: \n",
      "data/reference/transcriptome_index/ref_k31_fixed.fa\n",
      "--------------------------------------------------------------------------------\n",
      "Round 0, 0:134217728\n",
      "Pass\tFilling\tFiltering\n",
      "1\t2\t2\t\n",
      "2\t1\t0\n",
      "True junctions count = 10210\n",
      "False junctions count = 6152\n",
      "Hash table size = 16362\n",
      "Candidate marks count = 33190\n",
      "--------------------------------------------------------------------------------\n",
      "Reallocating bifurcations time: 0\n",
      "True marks count: 21435\n",
      "Edges construction time: 24\n",
      "--------------------------------------------------------------------------------\n",
      "Distinct junctions = 10210\n",
      "\n",
      "allowedIn: 17\n",
      "Max Junction ID: 10253\n",
      "seen.size():82033 kmerInfo.size():10254\n",
      "approximateContigTotalLength: 4949554\n",
      "counters for complex kmers:\n",
      "(prec>1 & succ>1)=8 | (succ>1 & isStart)=0 | (prec>1 & isEnd)=0 | (isStart & isEnd)=1\n",
      "contig count: 10431 element count: 5330463 complex nodes: 9\n",
      "# of ones in rank vector: 10430\n",
      "\u001b[00m[2022-05-29 17:30:14.243] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary file.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.243] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory data/reference/transcriptome_index\n",
      "\u001b[00msize = 5330463\n",
      "-----------------------------------------\n",
      "| Loading contigs | Time = 1.1134 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 567.31 us\n",
      "-----------------------------------------\n",
      "Number of ones: 10430\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "10430\n",
      "\u001b[00m[2022-05-29 17:30:14.255] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.256] [puff::index::jointLog] [info] contig count for validation: 10430\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.259] [puff::index::jointLog] [info] Total # of Contigs : 10430\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.259] [puff::index::jointLog] [info] Total # of numerical Contigs : 10430\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.259] [puff::index::jointLog] [info] Total # of contig vec entries: 16558\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.259] [puff::index::jointLog] [info] bits per offset entry 15\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.259] [puff::index::jointLog] [info] Done constructing the contig vector. 10431\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.261] [puff::index::jointLog] [info] # segments = 10430\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.261] [puff::index::jointLog] [info] total length = 5330463\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.263] [puff::index::jointLog] [info] Reading the reference files ...\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.306] [puff::index::jointLog] [info] positional integer width = 23\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.306] [puff::index::jointLog] [info] seqSize = 5330463\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.306] [puff::index::jointLog] [info] rankSize = 5330463\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.306] [puff::index::jointLog] [info] edgeVecSize = 0\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.306] [puff::index::jointLog] [info] num keys = 5017563\n",
      "\u001b[00mfor info, total work write each  : 2.331    total work inram from level 3 : 4.322  total work raw : 25.000 \n",
      "[Building BooPHF]  100  %   elapsed:   0 min 0  sec   remaining:   0 min 0  sec\n",
      "Bitarray        26296128  bits (100.00 %)   (array + ranks )\n",
      "final hash             0  bits (0.00 %) (nb in final hash 0)\n",
      "\u001b[00m[2022-05-29 17:30:14.635] [puff::index::jointLog] [info] mphf size = 3.13474 MB\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.638] [puff::index::jointLog] [info] chunk size = 666308\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.649] [puff::index::jointLog] [info] chunk 0 = [0, 666308)\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.649] [puff::index::jointLog] [info] chunk 1 = [666308, 1332616)\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.649] [puff::index::jointLog] [info] chunk 2 = [1332616, 1998924)\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.649] [puff::index::jointLog] [info] chunk 3 = [1998924, 2665232)\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.649] [puff::index::jointLog] [info] chunk 4 = [2665232, 3331540)\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.650] [puff::index::jointLog] [info] chunk 5 = [3331540, 3997848)\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.650] [puff::index::jointLog] [info] chunk 6 = [3997848, 4664156)\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.650] [puff::index::jointLog] [info] chunk 7 = [4664156, 5330433)\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.936] [puff::index::jointLog] [info] finished populating pos vector\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:14.936] [puff::index::jointLog] [info] writing index components\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:15.003] [puff::index::jointLog] [info] finished writing dense pufferfish index\n",
      "\u001b[00m[2022-05-29 17:30:15.006] [jLog] [info] done building index\n",
      "17:30:15\n"
     ]
    }
   ],
   "source": [
    "!salmon index -t data/reference/GCF_001632805.1_transcriptome_reference_w_decoy.fa -p 8 -i data/reference/transcriptome_index --decoys data/reference/decoys.txt -k 31 --keepDuplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 10: Run Salmon to Map Reads to Transcripts and Quantify Expression Levels\n",
    "Salmon aligns the trimmed reads to the reference transcriptome and generates the read counts per transcript. In this analysis, each gene has a single transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version Info: ### PLEASE UPGRADE SALMON ###\n",
      "### A newer version of salmon with important bug fixes and improvements is available. ####\n",
      "###\n",
      "The newest version, available at https://github.com/COMBINE-lab/salmon/releases\n",
      "contains new features, improvements, and bug fixes; please upgrade at your\n",
      "earliest convenience.\n",
      "###\n",
      "Sign up for the salmon mailing list to hear about new versions, features and updates at:\n",
      "https://oceangenomics.com/subscribe\n",
      "### salmon (selective-alignment-based) v1.7.0\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { /home/jupyter/rnaseq-myco-notebook/data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349122_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 8 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349122_quant }\n",
      "Logs will be written to data/quants/SRR13349122_quant/logs\n",
      "\u001b[00m[2022-05-29 17:30:15.323] [jointLog] [info] setting maxHashResizeThreads to 8\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:15.323] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:15.323] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:15.323] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:15.323] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:15.324] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:15.324] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:15.324] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 2.0345 ms\n",
      "-----------------------------------------\n",
      "size = 10431\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 130.82 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 23.617 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 2.3595 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "Number of ones: 10430\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 10.286 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.1251 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 10.6 ms\n",
      "-----------------------------------------\n",
      "size = 9684819\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 1.7373 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 40.183 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2022-05-29 17:30:15.353] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:15.395] [jointLog] [info] Index contained 4907 targets\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:15.397] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:15.397] [jointLog] [info] First decoy index : 4906 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10500000 \u001b[32mfragments\u001b[0m\n",
      "hits: 10015225; hits per frag:  0.956858\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2022-05-29 17:30:35.343] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:35.343] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:35.343] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:35.344] [jointLog] [info] Thread saw mini-batch with a maximum of 0.40% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:35.344] [jointLog] [info] Thread saw mini-batch with a maximum of 0.44% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:35.348] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:35.352] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:35.358] [jointLog] [info] Thread saw mini-batch with a maximum of 0.42% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:35.384] [jointLog] [info] Computed 4595 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:35.384] [jointLog] [info] Counted 10287659 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:35.388] [jointLog] [info] Number of mappings discarded because of alignment score : 152096\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:35.388] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 133954\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:35.388] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 72939\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:35.388] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:35.388] [jointLog] [info] Mapping rate = 95.1656%\n",
      "\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:35.388] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:35.389] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:35.392] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:35.392] [jointLog] [info] iteration = 0 | max rel diff. = 3330.2\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:35.453] [jointLog] [info] iteration = 100 | max rel diff. = 1.62461e-16\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:35.454] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:35.454] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Info: ### PLEASE UPGRADE SALMON ###\n",
      "### A newer version of salmon with important bug fixes and improvements is available. ####\n",
      "###\n",
      "The newest version, available at https://github.com/COMBINE-lab/salmon/releases\n",
      "contains new features, improvements, and bug fixes; please upgrade at your\n",
      "earliest convenience.\n",
      "###\n",
      "Sign up for the salmon mailing list to hear about new versions, features and updates at:\n",
      "https://oceangenomics.com/subscribe\n",
      "### salmon (selective-alignment-based) v1.7.0\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { /home/jupyter/rnaseq-myco-notebook/data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349123_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 8 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349123_quant }\n",
      "Logs will be written to data/quants/SRR13349123_quant/logs\n",
      "\u001b[00m[2022-05-29 17:30:36.071] [jointLog] [info] setting maxHashResizeThreads to 8\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:36.071] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:36.071] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:36.071] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:36.071] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:36.071] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:36.071] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:36.071] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 2.0162 ms\n",
      "-----------------------------------------\n",
      "size = 10431\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 94.434 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 18.693 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 2.3961 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "Number of ones: 10430\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 10.211 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.0355 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 11.172 ms\n",
      "-----------------------------------------\n",
      "size = 9684819\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 1.9004 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 32.575 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2022-05-29 17:30:36.100] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:36.141] [jointLog] [info] Index contained 4907 targets\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:36.143] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:36.143] [jointLog] [info] First decoy index : 4906 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000002 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11000000 \u001b[32mfragments\u001b[0m\n",
      "hits: 10546659; hits per frag:  0.962494\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2022-05-29 17:30:56.436] [jointLog] [info] Thread saw mini-batch with a maximum of 0.42% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:56.436] [jointLog] [info] Thread saw mini-batch with a maximum of 0.44% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:56.437] [jointLog] [info] Thread saw mini-batch with a maximum of 0.42% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:56.437] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:56.440] [jointLog] [info] Thread saw mini-batch with a maximum of 0.46% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:56.443] [jointLog] [info] Thread saw mini-batch with a maximum of 0.48% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:56.448] [jointLog] [info] Thread saw mini-batch with a maximum of 0.48% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:56.457] [jointLog] [info] Thread saw mini-batch with a maximum of 0.46% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:56.484] [jointLog] [info] Computed 4657 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:56.484] [jointLog] [info] Counted 10613007 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:56.488] [jointLog] [info] Number of mappings discarded because of alignment score : 158751\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:56.488] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 143045\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:56.488] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 80723\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:56.488] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:56.488] [jointLog] [info] Mapping rate = 95.6449%\n",
      "\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:56.488] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:56.488] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:56.492] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:56.492] [jointLog] [info] iteration = 0 | max rel diff. = 3407.4\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:56.553] [jointLog] [info] iteration = 100 | max rel diff. = 0\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:56.554] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:56.554] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Info: ### PLEASE UPGRADE SALMON ###\n",
      "### A newer version of salmon with important bug fixes and improvements is available. ####\n",
      "###\n",
      "The newest version, available at https://github.com/COMBINE-lab/salmon/releases\n",
      "contains new features, improvements, and bug fixes; please upgrade at your\n",
      "earliest convenience.\n",
      "###\n",
      "Sign up for the salmon mailing list to hear about new versions, features and updates at:\n",
      "https://oceangenomics.com/subscribe\n",
      "### salmon (selective-alignment-based) v1.7.0\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { /home/jupyter/rnaseq-myco-notebook/data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349124_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 8 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349124_quant }\n",
      "Logs will be written to data/quants/SRR13349124_quant/logs\n",
      "\u001b[00m[2022-05-29 17:30:57.342] [jointLog] [info] setting maxHashResizeThreads to 8\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:57.342] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:57.342] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:57.342] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:57.342] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:57.342] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:57.342] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:57.342] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 1.8692 ms\n",
      "-----------------------------------------\n",
      "size = 10431\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 113.59 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 17.634 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 2.4613 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "Number of ones: 10430\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 10.242 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.0541 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 10.376 ms\n",
      "-----------------------------------------\n",
      "size = 9684819\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 1.7686 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 35.693 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2022-05-29 17:30:57.370] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:57.411] [jointLog] [info] Index contained 4907 targets\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:57.413] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:30:57.413] [jointLog] [info] First decoy index : 4906 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10500000 \u001b[32mfragments\u001b[0m\n",
      "hits: 9990632; hits per frag:  0.953937\u001b[00m[2022-05-29 17:31:17.610] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:17.610] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:17.610] [jointLog] [info] Thread saw mini-batch with a maximum of 0.30% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:17.611] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:17.612] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:17.613] [jointLog] [info] Thread saw mini-batch with a maximum of 0.30% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:17.622] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:17.629] [jointLog] [info] Thread saw mini-batch with a maximum of 0.28% zero probability fragments\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2022-05-29 17:31:17.656] [jointLog] [info] Computed 4575 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:17.656] [jointLog] [info] Counted 10172390 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:17.660] [jointLog] [info] Number of mappings discarded because of alignment score : 187877\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:17.660] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 144611\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:17.660] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 64442\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:17.660] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:17.660] [jointLog] [info] Mapping rate = 94.9788%\n",
      "\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:17.660] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:17.661] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:17.663] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:17.664] [jointLog] [info] iteration = 0 | max rel diff. = 1650.82\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:17.725] [jointLog] [info] iteration = 100 | max rel diff. = 1.4345e-16\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:17.726] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:17.726] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Info: ### PLEASE UPGRADE SALMON ###\n",
      "### A newer version of salmon with important bug fixes and improvements is available. ####\n",
      "###\n",
      "The newest version, available at https://github.com/COMBINE-lab/salmon/releases\n",
      "contains new features, improvements, and bug fixes; please upgrade at your\n",
      "earliest convenience.\n",
      "###\n",
      "Sign up for the salmon mailing list to hear about new versions, features and updates at:\n",
      "https://oceangenomics.com/subscribe\n",
      "### salmon (selective-alignment-based) v1.7.0\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { /home/jupyter/rnaseq-myco-notebook/data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349125_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 8 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349125_quant }\n",
      "Logs will be written to data/quants/SRR13349125_quant/logs\n",
      "\u001b[00m[2022-05-29 17:31:18.596] [jointLog] [info] setting maxHashResizeThreads to 8\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:18.596] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:18.596] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:18.596] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:18.596] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:18.596] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:18.596] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:18.596] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 1.8127 ms\n",
      "-----------------------------------------\n",
      "size = 10431\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 97.469 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 17.397 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 2.3331 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "Number of ones: 10430\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 10.549 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.067 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 10.717 ms\n",
      "-----------------------------------------\n",
      "size = 9684819\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 1.8396 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 38.407 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2022-05-29 17:31:18.625] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:18.667] [jointLog] [info] Index contained 4907 targets\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:18.668] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:18.668] [jointLog] [info] First decoy index : 4906 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10500000 \u001b[32mfragments\u001b[0m\n",
      "hits: 10044460; hits per frag:  0.957616\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2022-05-29 17:31:38.768] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:38.776] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:38.778] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:38.780] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:38.789] [jointLog] [info] Thread saw mini-batch with a maximum of 0.40% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:38.791] [jointLog] [info] Thread saw mini-batch with a maximum of 0.42% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:38.795] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:38.797] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:38.825] [jointLog] [info] Computed 4586 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:38.825] [jointLog] [info] Counted 10429221 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:38.829] [jointLog] [info] Number of mappings discarded because of alignment score : 190142\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:38.829] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 150020\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:38.829] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 70256\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:38.829] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:38.829] [jointLog] [info] Mapping rate = 95.4666%\n",
      "\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:38.829] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:38.829] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:38.832] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:38.833] [jointLog] [info] iteration = 0 | max rel diff. = 1681.61\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:38.891] [jointLog] [info] iteration = 100 | max rel diff. = 1.62169e-16\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:38.892] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:38.892] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Info: ### PLEASE UPGRADE SALMON ###\n",
      "### A newer version of salmon with important bug fixes and improvements is available. ####\n",
      "###\n",
      "The newest version, available at https://github.com/COMBINE-lab/salmon/releases\n",
      "contains new features, improvements, and bug fixes; please upgrade at your\n",
      "earliest convenience.\n",
      "###\n",
      "Sign up for the salmon mailing list to hear about new versions, features and updates at:\n",
      "https://oceangenomics.com/subscribe\n",
      "### salmon (selective-alignment-based) v1.7.0\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { /home/jupyter/rnaseq-myco-notebook/data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349126_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 8 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349126_quant }\n",
      "Logs will be written to data/quants/SRR13349126_quant/logs\n",
      "\u001b[00m[2022-05-29 17:31:39.862] [jointLog] [info] setting maxHashResizeThreads to 8\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:39.862] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:39.862] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:39.862] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:39.862] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:39.862] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:39.862] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:39.862] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 1.8244 ms\n",
      "-----------------------------------------\n",
      "size = 10431\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 99.391 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 20.254 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 2.2472 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "Number of ones: 10430\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 10.001 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.0024 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 10.271 ms\n",
      "-----------------------------------------\n",
      "size = 9684819\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 1.8394 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 32.702 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2022-05-29 17:31:39.890] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:39.932] [jointLog] [info] Index contained 4907 targets\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:39.933] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:31:39.933] [jointLog] [info] First decoy index : 4906 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000002 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12000000 \u001b[32mfragments\u001b[0m\n",
      "hits: 11496195; hits per frag:  0.959012\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2022-05-29 17:32:02.447] [jointLog] [info] Thread saw mini-batch with a maximum of 0.28% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:02.447] [jointLog] [info] Thread saw mini-batch with a maximum of 0.26% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:02.447] [jointLog] [info] Thread saw mini-batch with a maximum of 0.30% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:02.460] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:02.465] [jointLog] [info] Thread saw mini-batch with a maximum of 0.28% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:02.466] [jointLog] [info] Thread saw mini-batch with a maximum of 0.26% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:02.468] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:02.470] [jointLog] [info] Thread saw mini-batch with a maximum of 0.30% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:02.498] [jointLog] [info] Computed 4591 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:02.498] [jointLog] [info] Counted 11715938 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:02.502] [jointLog] [info] Number of mappings discarded because of alignment score : 186660\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:02.502] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 144709\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:02.502] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 65046\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:02.502] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:02.502] [jointLog] [info] Mapping rate = 95.6559%\n",
      "\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:02.502] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:02.503] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:02.506] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:02.507] [jointLog] [info] iteration = 0 | max rel diff. = 1827.75\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:02.567] [jointLog] [info] iteration = 100 | max rel diff. = 0\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:02.568] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:02.568] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Info: ### PLEASE UPGRADE SALMON ###\n",
      "### A newer version of salmon with important bug fixes and improvements is available. ####\n",
      "###\n",
      "The newest version, available at https://github.com/COMBINE-lab/salmon/releases\n",
      "contains new features, improvements, and bug fixes; please upgrade at your\n",
      "earliest convenience.\n",
      "###\n",
      "Sign up for the salmon mailing list to hear about new versions, features and updates at:\n",
      "https://oceangenomics.com/subscribe\n",
      "### salmon (selective-alignment-based) v1.7.0\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { /home/jupyter/rnaseq-myco-notebook/data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349127_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 8 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349127_quant }\n",
      "Logs will be written to data/quants/SRR13349127_quant/logs\n",
      "\u001b[00m[2022-05-29 17:32:03.119] [jointLog] [info] setting maxHashResizeThreads to 8\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:03.119] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:03.119] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:03.119] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:03.119] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:03.119] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:03.119] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:03.119] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 2.0244 ms\n",
      "-----------------------------------------\n",
      "size = 10431\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 102.7 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 16.1 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 2.4278 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "Number of ones: 10430\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 10.137 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.0936 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 11.009 ms\n",
      "-----------------------------------------\n",
      "size = 9684819\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 2.0055 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 40.072 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2022-05-29 17:32:03.148] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:03.190] [jointLog] [info] Index contained 4907 targets\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:03.191] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:03.191] [jointLog] [info] First decoy index : 4906 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500059 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12000000 \u001b[32mfragments\u001b[0m\n",
      "hits: 11555781; hits per frag:  0.965671\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2022-05-29 17:32:26.038] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.039] [jointLog] [info] Thread saw mini-batch with a maximum of 0.30% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.040] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.064] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.065] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.066] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.067] [jointLog] [info] Thread saw mini-batch with a maximum of 0.28% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.068] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.094] [jointLog] [info] Computed 4632 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.094] [jointLog] [info] Counted 12002454 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.098] [jointLog] [info] Number of mappings discarded because of alignment score : 188621\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.098] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 150239\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.098] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 70855\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.098] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.098] [jointLog] [info] Mapping rate = 96.1307%\n",
      "\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.098] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.099] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.102] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.103] [jointLog] [info] iteration = 0 | max rel diff. = 3717.9\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.163] [jointLog] [info] iteration = 100 | max rel diff. = 1.48465e-16\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.164] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.164] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Info: ### PLEASE UPGRADE SALMON ###\n",
      "### A newer version of salmon with important bug fixes and improvements is available. ####\n",
      "###\n",
      "The newest version, available at https://github.com/COMBINE-lab/salmon/releases\n",
      "contains new features, improvements, and bug fixes; please upgrade at your\n",
      "earliest convenience.\n",
      "###\n",
      "Sign up for the salmon mailing list to hear about new versions, features and updates at:\n",
      "https://oceangenomics.com/subscribe\n",
      "### salmon (selective-alignment-based) v1.7.0\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { /home/jupyter/rnaseq-myco-notebook/data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349128_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 8 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349128_quant }\n",
      "Logs will be written to data/quants/SRR13349128_quant/logs\n",
      "\u001b[00m[2022-05-29 17:32:26.875] [jointLog] [info] setting maxHashResizeThreads to 8\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.875] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.875] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.875] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.875] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.875] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.875] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.875] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 1.7273 ms\n",
      "-----------------------------------------\n",
      "size = 10431\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 100.83 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 18.729 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 2.3354 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "Number of ones: 10430\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 10.023 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.2863 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 10.607 ms\n",
      "-----------------------------------------\n",
      "size = 9684819\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 1.9869 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 37.636 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2022-05-29 17:32:26.903] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.947] [jointLog] [info] Index contained 4907 targets\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.948] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:26.948] [jointLog] [info] First decoy index : 4906 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12500000 \u001b[32mfragments\u001b[0m\n",
      "hits: 11847463; hits per frag:  0.951493\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2022-05-29 17:32:50.308] [jointLog] [info] Thread saw mini-batch with a maximum of 0.28% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:50.308] [jointLog] [info] Thread saw mini-batch with a maximum of 0.26% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:50.309] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:50.309] [jointLog] [info] Thread saw mini-batch with a maximum of 0.26% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:50.311] [jointLog] [info] Thread saw mini-batch with a maximum of 0.26% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:50.315] [jointLog] [info] Thread saw mini-batch with a maximum of 0.28% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:50.317] [jointLog] [info] Thread saw mini-batch with a maximum of 0.26% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:50.324] [jointLog] [info] Thread saw mini-batch with a maximum of 0.28% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:50.350] [jointLog] [info] Computed 4521 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:50.350] [jointLog] [info] Counted 11952118 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:50.354] [jointLog] [info] Number of mappings discarded because of alignment score : 443265\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:50.354] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 259906\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:50.354] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 48485\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:50.354] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:50.354] [jointLog] [info] Mapping rate = 94.618%\n",
      "\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:50.354] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:50.355] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:50.358] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:50.358] [jointLog] [info] iteration = 0 | max rel diff. = 1853.46\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:50.418] [jointLog] [info] iteration = 100 | max rel diff. = 0\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:50.419] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:50.419] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Info: ### PLEASE UPGRADE SALMON ###\n",
      "### A newer version of salmon with important bug fixes and improvements is available. ####\n",
      "###\n",
      "The newest version, available at https://github.com/COMBINE-lab/salmon/releases\n",
      "contains new features, improvements, and bug fixes; please upgrade at your\n",
      "earliest convenience.\n",
      "###\n",
      "Sign up for the salmon mailing list to hear about new versions, features and updates at:\n",
      "https://oceangenomics.com/subscribe\n",
      "### salmon (selective-alignment-based) v1.7.0\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { /home/jupyter/rnaseq-myco-notebook/data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349129_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 8 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349129_quant }\n",
      "Logs will be written to data/quants/SRR13349129_quant/logs\n",
      "\u001b[00m[2022-05-29 17:32:51.124] [jointLog] [info] setting maxHashResizeThreads to 8\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:51.124] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:51.124] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:51.124] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:51.124] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:51.124] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:51.124] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:51.124] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 2.1488 ms\n",
      "-----------------------------------------\n",
      "size = 10431\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 112.71 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 17.259 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 2.3563 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "Number of ones: 10430\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 10.306 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.0794 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 10.511 ms\n",
      "-----------------------------------------\n",
      "size = 9684819\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 1.8588 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 34.125 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2022-05-29 17:32:51.153] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:51.195] [jointLog] [info] Index contained 4907 targets\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:51.196] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:32:51.196] [jointLog] [info] First decoy index : 4906 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 1000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12500000 \u001b[32mfragments\u001b[0m\n",
      "hits: 11907033; hits per frag:  0.953615\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2022-05-29 17:33:15.176] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.191] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.196] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.198] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.200] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.204] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.206] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.207] [jointLog] [info] Thread saw mini-batch with a maximum of 0.30% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.234] [jointLog] [info] Computed 4572 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.234] [jointLog] [info] Counted 12250892 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.238] [jointLog] [info] Number of mappings discarded because of alignment score : 443985\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.238] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 265177\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.238] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 54924\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.238] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.238] [jointLog] [info] Mapping rate = 95.1013%\n",
      "\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.238] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.238] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.241] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.242] [jointLog] [info] iteration = 0 | max rel diff. = 3769.81\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.303] [jointLog] [info] iteration = 100 | max rel diff. = 1.66867e-16\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.304] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.304] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Info: ### PLEASE UPGRADE SALMON ###\n",
      "### A newer version of salmon with important bug fixes and improvements is available. ####\n",
      "###\n",
      "The newest version, available at https://github.com/COMBINE-lab/salmon/releases\n",
      "contains new features, improvements, and bug fixes; please upgrade at your\n",
      "earliest convenience.\n",
      "###\n",
      "Sign up for the salmon mailing list to hear about new versions, features and updates at:\n",
      "https://oceangenomics.com/subscribe\n",
      "### salmon (selective-alignment-based) v1.7.0\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { /home/jupyter/rnaseq-myco-notebook/data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349130_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 8 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349130_quant }\n",
      "Logs will be written to data/quants/SRR13349130_quant/logs\n",
      "\u001b[00m[2022-05-29 17:33:15.881] [jointLog] [info] setting maxHashResizeThreads to 8\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.881] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.881] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.881] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.881] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.881] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.881] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.881] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 1.7877 ms\n",
      "-----------------------------------------\n",
      "size = 10431\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 99.797 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 20.84 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 2.5903 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "Number of ones: 10430\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 10.22 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.0668 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 11.061 ms\n",
      "-----------------------------------------\n",
      "size = 9684819\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 1.8292 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 36.451 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2022-05-29 17:33:15.910] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.953] [jointLog] [info] Index contained 4907 targets\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.954] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:15.954] [jointLog] [info] First decoy index : 4906 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000015 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000000 \u001b[32mfragments\u001b[0m\n",
      "hits: 9580701; hits per frag:  0.959976\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2022-05-29 17:33:34.300] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:34.300] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:34.301] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:34.306] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:34.307] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:34.310] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:34.311] [jointLog] [info] Thread saw mini-batch with a maximum of 0.30% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:34.315] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:34.343] [jointLog] [info] Computed 4484 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:34.343] [jointLog] [info] Counted 9628756 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:34.346] [jointLog] [info] Number of mappings discarded because of alignment score : 163164\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:34.346] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 115960\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:34.346] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 44119\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:34.346] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:34.346] [jointLog] [info] Mapping rate = 95.646%\n",
      "\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:34.346] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:34.347] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:34.349] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:34.350] [jointLog] [info] iteration = 0 | max rel diff. = 1583.88\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:34.410] [jointLog] [info] iteration = 100 | max rel diff. = 1.35198e-16\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:34.411] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:34.411] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Info: ### PLEASE UPGRADE SALMON ###\n",
      "### A newer version of salmon with important bug fixes and improvements is available. ####\n",
      "###\n",
      "The newest version, available at https://github.com/COMBINE-lab/salmon/releases\n",
      "contains new features, improvements, and bug fixes; please upgrade at your\n",
      "earliest convenience.\n",
      "###\n",
      "Sign up for the salmon mailing list to hear about new versions, features and updates at:\n",
      "https://oceangenomics.com/subscribe\n",
      "### salmon (selective-alignment-based) v1.7.0\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { /home/jupyter/rnaseq-myco-notebook/data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349131_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 8 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349131_quant }\n",
      "Logs will be written to data/quants/SRR13349131_quant/logs\n",
      "\u001b[00m[2022-05-29 17:33:35.141] [jointLog] [info] setting maxHashResizeThreads to 8\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:35.141] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:35.141] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:35.142] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:35.142] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:35.142] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:35.142] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:35.142] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 1.7531 ms\n",
      "-----------------------------------------\n",
      "size = 10431\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 86.512 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 17.06 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 2.3486 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "Number of ones: 10430\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 9.9707 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.0604 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 10.179 ms\n",
      "-----------------------------------------\n",
      "size = 9684819\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 1.7516 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 37.305 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2022-05-29 17:33:35.169] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:35.212] [jointLog] [info] Index contained 4907 targets\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:35.213] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:35.213] [jointLog] [info] First decoy index : 4906 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000000 \u001b[32mfragments\u001b[0m\n",
      "hits: 9635719; hits per frag:  0.966667\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2022-05-29 17:33:54.215] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.220] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.222] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.222] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.232] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.232] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.237] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.239] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.266] [jointLog] [info] Computed 4550 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.266] [jointLog] [info] Counted 10028030 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.269] [jointLog] [info] Number of mappings discarded because of alignment score : 168772\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.269] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 123620\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.269] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 50352\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.269] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.269] [jointLog] [info] Mapping rate = 96.1719%\n",
      "\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.269] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.270] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.273] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.274] [jointLog] [info] iteration = 0 | max rel diff. = 1633.38\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.335] [jointLog] [info] iteration = 100 | max rel diff. = 1.84245e-16\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.336] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.336] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Info: ### PLEASE UPGRADE SALMON ###\n",
      "### A newer version of salmon with important bug fixes and improvements is available. ####\n",
      "###\n",
      "The newest version, available at https://github.com/COMBINE-lab/salmon/releases\n",
      "contains new features, improvements, and bug fixes; please upgrade at your\n",
      "earliest convenience.\n",
      "###\n",
      "Sign up for the salmon mailing list to hear about new versions, features and updates at:\n",
      "https://oceangenomics.com/subscribe\n",
      "### salmon (selective-alignment-based) v1.7.0\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { /home/jupyter/rnaseq-myco-notebook/data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349132_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 8 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349132_quant }\n",
      "Logs will be written to data/quants/SRR13349132_quant/logs\n",
      "\u001b[00m[2022-05-29 17:33:54.892] [jointLog] [info] setting maxHashResizeThreads to 8\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.892] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.892] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.892] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.892] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.892] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.892] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.892] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 1.8753 ms\n",
      "-----------------------------------------\n",
      "size = 10431\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 94.124 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 17.194 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 2.3539 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "Number of ones: 10430\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 9.9806 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 996.12 us\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 10.499 ms\n",
      "-----------------------------------------\n",
      "size = 9684819\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 1.8015 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 39.53 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2022-05-29 17:33:54.920] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.963] [jointLog] [info] Index contained 4907 targets\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.964] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:33:54.964] [jointLog] [info] First decoy index : 4906 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11000001 \u001b[32mfragments\u001b[0m\n",
      "hits: 10524275; hits per frag:  0.957849\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2022-05-29 17:34:16.317] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:16.318] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:16.318] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:16.319] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:16.327] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:16.330] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:16.334] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:16.336] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:16.363] [jointLog] [info] Computed 4570 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:16.363] [jointLog] [info] Counted 10811229 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:16.367] [jointLog] [info] Number of mappings discarded because of alignment score : 182403\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:16.367] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 138010\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:16.367] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 62855\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:16.367] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:16.367] [jointLog] [info] Mapping rate = 95.4795%\n",
      "\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:16.367] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:16.367] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:16.371] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:16.371] [jointLog] [info] iteration = 0 | max rel diff. = 1726.4\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:16.433] [jointLog] [info] iteration = 100 | max rel diff. = 1.68972e-16\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:16.433] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:16.433] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Info: ### PLEASE UPGRADE SALMON ###\n",
      "### A newer version of salmon with important bug fixes and improvements is available. ####\n",
      "###\n",
      "The newest version, available at https://github.com/COMBINE-lab/salmon/releases\n",
      "contains new features, improvements, and bug fixes; please upgrade at your\n",
      "earliest convenience.\n",
      "###\n",
      "Sign up for the salmon mailing list to hear about new versions, features and updates at:\n",
      "https://oceangenomics.com/subscribe\n",
      "### salmon (selective-alignment-based) v1.7.0\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { /home/jupyter/rnaseq-myco-notebook/data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349133_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 8 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349133_quant }\n",
      "Logs will be written to data/quants/SRR13349133_quant/logs\n",
      "\u001b[00m[2022-05-29 17:34:17.153] [jointLog] [info] setting maxHashResizeThreads to 8\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:17.153] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:17.153] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:17.153] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:17.153] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:17.153] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:17.153] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:17.153] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 1.7184 ms\n",
      "-----------------------------------------\n",
      "size = 10431\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 101.48 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 20.139 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 2.3836 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "Number of ones: 10430\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 9.9848 ms\n",
      "-----------------------------------------\n",
      "size = 5330463\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.0471 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 10.15 ms\n",
      "-----------------------------------------\n",
      "size = 9684819\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 1.8177 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 35.503 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2022-05-29 17:34:17.181] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:17.225] [jointLog] [info] Index contained 4907 targets\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:17.226] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:17.226] [jointLog] [info] First decoy index : 4906 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11500000 \u001b[32mfragments\u001b[0m\n",
      "hits: 11057995; hits per frag:  0.963044\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2022-05-29 17:34:38.592] [jointLog] [info] Thread saw mini-batch with a maximum of 0.42% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:38.596] [jointLog] [info] Thread saw mini-batch with a maximum of 0.48% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:38.597] [jointLog] [info] Thread saw mini-batch with a maximum of 0.44% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:38.597] [jointLog] [info] Thread saw mini-batch with a maximum of 0.42% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:38.598] [jointLog] [info] Thread saw mini-batch with a maximum of 0.42% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:38.607] [jointLog] [info] Thread saw mini-batch with a maximum of 0.44% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:38.620] [jointLog] [info] Thread saw mini-batch with a maximum of 0.42% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:38.621] [jointLog] [info] Thread saw mini-batch with a maximum of 0.46% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:38.648] [jointLog] [info] Computed 4585 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:38.648] [jointLog] [info] Counted 11060584 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:38.651] [jointLog] [info] Number of mappings discarded because of alignment score : 185118\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:38.651] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 144946\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:38.651] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 69884\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:38.651] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:38.651] [jointLog] [info] Mapping rate = 95.9172%\n",
      "\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:38.651] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:38.652] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:38.655] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:38.656] [jointLog] [info] iteration = 0 | max rel diff. = 1755\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:38.717] [jointLog] [info] iteration = 100 | max rel diff. = 1.01982e-12\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:38.717] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:38.717] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00m17:34:39\n"
     ]
    }
   ],
   "source": [
    "!cat data/raw_fastq/list_of_accesionIDS.txt | xargs -I {} salmon quant -i /home/jupyter/rnaseq-myco-notebook/data/reference/transcriptome_index -l SR -r \"data/trimmed/{}_1_trimmed.fastq.gz\" -p 8 --validateMappings -o \"data/quants/{}_quant\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 11: Report the top 10 most highly expressed genes in the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 most highly expressed genes in each wild-type sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name\tLength\tEffectiveLength\tTPM\tNumReads\n",
      "rna-BB28_RS07080\t117\t3.947\t366889.819745\t16507.000\n",
      "rna-BB28_RS07075\t3116\t2866.000\t234649.688207\t7665384.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t130544.614501\t1883781.000\n",
      "rna-BB28_RS17330\t369\t119.000\t72555.739838\t98414.000\n",
      "gene-BB28_RS02220\t204\t9.377\t8373.726433\t895.000\n",
      "gene-BB28_RS20695\t231\t14.032\t6858.936071\t1097.000\n",
      "rna-BB28_RS09710\t405\t155.000\t5466.039721\t9657.000\n",
      "gene-BB28_RS18745\t300\t51.326\t3680.213081\t2153.000\n",
      "gene-BB28_RS18945\t222\t12.150\t3530.894602\t489.000\n",
      "gene-BB28_RS24750\t102\t3.543\t3392.339786\t137.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t348464.132877\t16529.000\n",
      "rna-BB28_RS07075\t3116\t2866.000\t224110.719521\t7718494.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t132619.568495\t2017600.000\n",
      "rna-BB28_RS17330\t369\t119.000\t76318.688035\t109137.000\n",
      "gene-BB28_RS02220\t204\t9.377\t8723.549796\t983.000\n",
      "gene-BB28_RS20695\t231\t14.032\t7312.353823\t1233.000\n",
      "rna-BB28_RS09710\t405\t155.000\t6225.085179\t11595.000\n",
      "gene-BB28_RS18745\t300\t51.326\t3998.213678\t2466.000\n",
      "gene-BB28_RS18945\t222\t12.150\t3773.735759\t551.000\n",
      "gene-BB28_RS24750\t102\t3.543\t3452.551034\t147.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t471373.491225\t23945.000\n",
      "rna-BB28_RS07075\t3116\t2866.000\t210066.635757\t7747975.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t109003.973827\t1775951.000\n",
      "rna-BB28_RS17330\t369\t119.000\t58941.596177\t90266.000\n",
      "gene-BB28_RS02220\t204\t9.377\t5709.495815\t689.000\n",
      "gene-BB28_RS20695\t231\t14.032\t5576.508929\t1007.000\n",
      "rna-BB28_RS09710\t405\t155.000\t4726.928047\t9429.000\n",
      "gene-BB28_RS18745\t300\t51.326\t2812.920437\t1858.000\n",
      "gene-BB28_RS18945\t222\t12.150\t2705.198053\t423.000\n",
      "gene-BB28_RS24750\t102\t3.543\t2653.670233\t121.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t454456.088270\t24081.000\n",
      "rna-BB28_RS07075\t3116\t2866.000\t202000.055452\t7771691.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t111292.575649\t1891419.000\n",
      "rna-BB28_RS17330\t369\t119.000\t63375.473250\t101241.000\n",
      "gene-BB28_RS02220\t204\t9.377\t5711.820118\t719.000\n",
      "rna-BB28_RS09710\t405\t155.000\t5621.535273\t11697.000\n",
      "gene-BB28_RS20695\t231\t14.032\t5568.978149\t1049.000\n",
      "gene-BB28_RS24750\t102\t3.543\t3132.672144\t149.000\n",
      "gene-BB28_RS18745\t300\t51.326\t2984.021469\t2056.000\n",
      "gene-BB28_RS18945\t222\t12.150\t2887.664276\t471.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t355610.619291\t16373.000\n",
      "rna-BB28_RS07075\t3116\t2866.000\t274208.716011\t9166768.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t127630.663764\t1884723.000\n",
      "rna-BB28_RS17330\t369\t119.000\t68728.626182\t95399.000\n",
      "gene-BB28_RS02220\t204\t9.377\t7442.161455\t814.000\n",
      "gene-BB28_RS20695\t231\t14.032\t6268.684864\t1026.000\n",
      "rna-BB28_RS09710\t405\t155.000\t4239.015431\t7664.000\n",
      "gene-BB28_RS18945\t222\t12.150\t3760.815719\t533.000\n",
      "gene-BB28_RS24750\t102\t3.543\t3411.747177\t141.000\n",
      "gene-BB28_RS18745\t300\t51.326\t2908.082049\t1741.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t342846.188962\t16587.000\n",
      "rna-BB28_RS07075\t3116\t2866.000\t261522.353002\t9186684.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t130870.033318\t2030709.000\n",
      "rna-BB28_RS17330\t369\t119.000\t72868.976078\t106283.000\n",
      "gene-BB28_RS02220\t204\t9.377\t7473.996129\t859.000\n",
      "gene-BB28_RS20695\t231\t14.032\t6268.055884\t1078.000\n",
      "rna-BB28_RS09710\t405\t155.000\t4786.846193\t9094.000\n",
      "gene-BB28_RS18945\t222\t12.150\t3773.776554\t562.000\n",
      "gene-BB28_RS18745\t300\t51.326\t3228.515158\t2031.000\n",
      "gene-BB28_RS24750\t102\t3.543\t2809.328861\t122.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n",
      "17:34:40\n"
     ]
    }
   ],
   "source": [
    "!head data/quants/SRR13349122_quant/quant.sf -n 1\n",
    "!sort -nrk 4,4 data/quants/SRR13349122_quant/quant.sf | head -10\n",
    "!sort -nrk 4,4 data/quants/SRR13349123_quant/quant.sf | head -10\n",
    "!sort -nrk 4,4 data/quants/SRR13349124_quant/quant.sf | head -10\n",
    "!sort -nrk 4,4 data/quants/SRR13349125_quant/quant.sf | head -10\n",
    "!sort -nrk 4,4 data/quants/SRR13349126_quant/quant.sf | head -10\n",
    "!sort -nrk 4,4 data/quants/SRR13349127_quant/quant.sf | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 most highly expressed genes in the double lysogen samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name\tLength\tEffectiveLength\tTPM\tNumReads\n",
      "rna-BB28_RS07080\t117\t3.947\t453962.554944\t24652.000\n",
      "rna-BB28_RS07075\t3116\t2866.000\t246655.204473\t9725319.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t92462.501485\t1610411.000\n",
      "rna-BB28_RS17330\t369\t119.000\t77568.389870\t126990.000\n",
      "gene-BB28_RS20695\t231\t14.032\t4926.415147\t951.000\n",
      "rna-BB28_RS09710\t405\t155.000\t4308.287043\t9187.000\n",
      "gene-BB28_RS02220\t204\t9.377\t3790.573785\t489.000\n",
      "gene-BB28_RS14885\t195\t8.348\t2603.559715\t299.000\n",
      "gene-BB28_RS06975\t216\t11.099\t2541.095506\t388.000\n",
      "gene-BB28_RS21780\t213\t10.625\t2223.501125\t325.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t437397.002569\t24834.000\n",
      "rna-BB28_RS07075\t3116\t2866.000\t237318.253525\t9783257.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t95599.035600\t1740858.000\n",
      "rna-BB28_RS17330\t369\t119.000\t83089.537568\t142223.000\n",
      "gene-BB28_RS20695\t231\t14.032\t5400.553107\t1090.000\n",
      "rna-BB28_RS09710\t405\t155.000\t5016.367275\t11184.000\n",
      "gene-BB28_RS02220\t204\t9.377\t4122.229249\t556.000\n",
      "gene-BB28_RS14885\t195\t8.348\t3206.404708\t385.000\n",
      "gene-BB28_RS06975\t216\t11.099\t2800.000048\t447.000\n",
      "gene-BB28_RS21780\t213\t10.625\t2434.210804\t372.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t400790.315794\t15594.000\n",
      "rna-BB28_RS07075\t3116\t2866.000\t280304.877022\t7918673.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t94999.070212\t1185492.000\n",
      "rna-BB28_RS17330\t369\t119.000\t76649.660848\t89909.000\n",
      "rna-BB28_RS09710\t405\t155.000\t4707.960295\t7193.000\n",
      "gene-BB28_RS02220\t204\t9.377\t4046.313376\t374.000\n",
      "gene-BB28_RS20695\t231\t14.032\t3998.226912\t553.000\n",
      "gene-BB28_RS14885\t195\t8.348\t2540.004334\t209.000\n",
      "gene-BB28_RS20665\t1293\t1043.000\t2491.034277\t25610.000\n",
      "gene-BB28_RS24750\t102\t3.543\t2118.862026\t74.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t382840.293956\t15621.000\n",
      "rna-BB28_RS07075\t3116\t2866.000\t273993.659363\t8117329.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t98392.106467\t1287628.000\n",
      "rna-BB28_RS17330\t369\t119.000\t81017.983597\t99661.000\n",
      "rna-BB28_RS09710\t405\t155.000\t5293.207433\t8481.000\n",
      "gene-BB28_RS02220\t204\t9.377\t4425.825879\t429.000\n",
      "gene-BB28_RS20695\t231\t14.032\t4357.210126\t632.000\n",
      "gene-BB28_RS14885\t195\t8.348\t3476.630578\t300.000\n",
      "gene-BB28_RS20665\t1293\t1043.000\t2925.185374\t31538.000\n",
      "gene-BB28_RS18745\t300\t51.326\t2320.215300\t1231.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t413489.577066\t19297.000\n",
      "rna-BB28_RS07075\t3116\t2866.000\t262171.629861\t8883669.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t78623.588158\t1176839.000\n",
      "rna-BB28_RS17330\t369\t119.000\t68320.253231\t96123.000\n",
      "rna-BB28_RS09710\t405\t155.000\t5474.804605\t10033.000\n",
      "gene-BB28_RS20695\t231\t14.032\t4894.557292\t812.000\n",
      "gene-BB28_RS02220\t204\t9.377\t4185.245841\t464.000\n",
      "gene-BB28_RS14885\t195\t8.348\t3627.323410\t358.000\n",
      "gene-BB28_RS20665\t1293\t1043.000\t3421.571432\t42193.000\n",
      "gene-BB28_RS18945\t222\t12.150\t2749.667941\t395.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t398339.037417\t19555.000\n",
      "rna-BB28_RS07075\t3116\t2866.000\t249742.504095\t8901821.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t80654.134701\t1269903.000\n",
      "rna-BB28_RS17330\t369\t119.000\t71668.251678\t106068.000\n",
      "rna-BB28_RS09710\t405\t155.000\t6362.987227\t12266.000\n",
      "gene-BB28_RS20695\t231\t14.032\t5415.137332\t945.000\n",
      "gene-BB28_RS02220\t204\t9.377\t4544.636394\t530.000\n",
      "gene-BB28_RS14885\t195\t8.348\t4093.666525\t425.000\n",
      "gene-BB28_RS20665\t1293\t1043.000\t3958.562219\t51349.000\n",
      "gene-BB28_RS06975\t216\t11.099\t2999.278403\t414.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n"
     ]
    }
   ],
   "source": [
    "!head data/quants/SRR13349122_quant/quant.sf -n 1\n",
    "!sort -nrk 4,4 data/quants/SRR13349128_quant/quant.sf | head -10\n",
    "!sort -nrk 4,4 data/quants/SRR13349129_quant/quant.sf | head -10\n",
    "!sort -nrk 4,4 data/quants/SRR13349130_quant/quant.sf | head -10\n",
    "!sort -nrk 4,4 data/quants/SRR13349131_quant/quant.sf | head -10\n",
    "!sort -nrk 4,4 data/quants/SRR13349132_quant/quant.sf | head -10\n",
    "!sort -nrk 4,4 data/quants/SRR13349133_quant/quant.sf | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 12: Report the expression of a putative acyl-ACP desaturase (BB28_RS16545) that was downregulated in the double lysogen relative to wild-type\n",
    "A acyl-transferase was reported to be downregulated in the double lysogen as shown in the table of the top 20 upregulated and downregulated genes from the paper describing the study.\n",
    "![RNA-Seq workflow](images/table-cushman.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `grep` to report the expression in the wild-type sample. The fields in the Salmon `quant.sf` file are as follows. The level of expression is reported in the Transcripts Per Million (`TPM`) and number of reads (`NumReads`) fields:  \n",
    "`Name    Length  EffectiveLength TPM     NumReads`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gene-BB28_RS16545\t987\t737.000\t53.330147\t448.000\n",
      "gene-BB28_RS16545\t987\t737.000\t50.245685\t445.000\n",
      "gene-BB28_RS16545\t987\t737.000\t42.489598\t403.000\n",
      "gene-BB28_RS16545\t987\t737.000\t44.574169\t441.000\n",
      "gene-BB28_RS16545\t987\t737.000\t52.578979\t452.000\n",
      "gene-BB28_RS16545\t987\t737.000\t53.912280\t487.000\n"
     ]
    }
   ],
   "source": [
    "!grep 'BB28_RS16545' data/quants/SRR13349122_quant/quant.sf\n",
    "!grep 'BB28_RS16545' data/quants/SRR13349123_quant/quant.sf\n",
    "!grep 'BB28_RS16545' data/quants/SRR13349124_quant/quant.sf\n",
    "!grep 'BB28_RS16545' data/quants/SRR13349125_quant/quant.sf\n",
    "!grep 'BB28_RS16545' data/quants/SRR13349126_quant/quant.sf\n",
    "!grep 'BB28_RS16545' data/quants/SRR13349127_quant/quant.sf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `grep` to report the expression in the double lysogen sample. The fields in the Salmon `quant.sf` file are as follows. The level of expression is reported in the Transcripts Per Million (`TPM`) and number of reads (`NumReads`) fields:  \n",
    "`Name    Length  EffectiveLength TPM     NumReads`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gene-BB28_RS16545\t987\t737.000\t4.635462\t47.000\n",
      "gene-BB28_RS16545\t987\t737.000\t6.508868\t69.000\n",
      "gene-BB28_RS16545\t987\t737.000\t5.093176\t37.000\n",
      "gene-BB28_RS16545\t987\t737.000\t5.906750\t45.000\n",
      "gene-BB28_RS16545\t987\t737.000\t4.934811\t43.000\n",
      "gene-BB28_RS16545\t987\t737.000\t6.218665\t57.000\n"
     ]
    }
   ],
   "source": [
    "!grep 'BB28_RS16545' data/quants/SRR13349128_quant/quant.sf\n",
    "!grep 'BB28_RS16545' data/quants/SRR13349129_quant/quant.sf\n",
    "!grep 'BB28_RS16545' data/quants/SRR13349130_quant/quant.sf\n",
    "!grep 'BB28_RS16545' data/quants/SRR13349131_quant/quant.sf\n",
    "!grep 'BB28_RS16545' data/quants/SRR13349132_quant/quant.sf\n",
    "!grep 'BB28_RS16545' data/quants/SRR13349133_quant/quant.sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 12: Combine Genecounts to a Single Genecount File\n",
    "Commonly, the readcounts for each sample are combined into a single table, where the rows contain the gene ID, and the columns identify the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version Info: ### PLEASE UPGRADE SALMON ###\n",
      "### A newer version of salmon with important bug fixes and improvements is available. ####\n",
      "###\n",
      "The newest version, available at https://github.com/COMBINE-lab/salmon/releases\n",
      "contains new features, improvements, and bug fixes; please upgrade at your\n",
      "earliest convenience.\n",
      "###\n",
      "Sign up for the salmon mailing list to hear about new versions, features and updates at:\n",
      "https://oceangenomics.com/subscribe\n",
      "\u001b[00m[2022-05-29 17:34:43.008] [mergeLog] [info] samples: [ data/quants/SRR13349122_quant, data/quants/SRR13349123_quant, data/quants/SRR13349124_quant, data/quants/SRR13349125_quant, data/quants/SRR13349126_quant, data/quants/SRR13349127_quant, data/quants/SRR13349128_quant, data/quants/SRR13349129_quant, data/quants/SRR13349130_quant, data/quants/SRR13349131_quant, data/quants/SRR13349132_quant, data/quants/SRR13349133_quant ]\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:43.008] [mergeLog] [info] sample names : [ SRR13349122_quant, SRR13349123_quant, SRR13349124_quant, SRR13349125_quant, SRR13349126_quant, SRR13349127_quant, SRR13349128_quant, SRR13349129_quant, SRR13349130_quant, SRR13349131_quant, SRR13349132_quant, SRR13349133_quant ]\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:43.008] [mergeLog] [info] output column : NUMREADS\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:43.008] [mergeLog] [info] output file : data/quants/merged_quants.txt\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:43.008] [mergeLog] [info] Parsing data/quants/SRR13349122_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:43.017] [mergeLog] [info] Parsing data/quants/SRR13349123_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:43.027] [mergeLog] [info] Parsing data/quants/SRR13349124_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:43.037] [mergeLog] [info] Parsing data/quants/SRR13349125_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:43.046] [mergeLog] [info] Parsing data/quants/SRR13349126_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:43.057] [mergeLog] [info] Parsing data/quants/SRR13349127_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:43.066] [mergeLog] [info] Parsing data/quants/SRR13349128_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:43.075] [mergeLog] [info] Parsing data/quants/SRR13349129_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:43.084] [mergeLog] [info] Parsing data/quants/SRR13349130_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:43.095] [mergeLog] [info] Parsing data/quants/SRR13349131_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:43.104] [mergeLog] [info] Parsing data/quants/SRR13349132_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2022-05-29 17:34:43.113] [mergeLog] [info] Parsing data/quants/SRR13349133_quant/quant.sf\n",
      "\u001b[00m"
     ]
    }
   ],
   "source": [
    "##first merge salmon files by number of reads.\n",
    "!salmon quantmerge --column numreads --quants data/quants/*_quant -o data/quants/merged_quants.txt\n",
    "##optinally we can rename the columns\n",
    "!sed -i \"1s/.*/Name\\tSRR13349122\\tSRR13349123\\tSRR13349124\\tSRR13349125\\tSRR13349126\\tSRR13349127\\tSRR13349128\\tSRR13349129\\tSRR13349130\\tSRR13349131\\tSRR13349132\\tSRR13349133/\" data/quants/merged_quants.txt\n",
    "\n",
    "##for further formatting, it may be easier in our r-code to later merge\n",
    "##if we remove the gene- and rna- prefix\n",
    "!sed -i \"s/gene-//\" data/quants/merged_quants.txt\n",
    "!sed -i \"s/rna-//\" data/quants/merged_quants.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <a name=\"workflow\">Additional Workflows</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have read counts per gene, feel free to explore the R workflow which creates plots and analyses using these readcount files, or try other alternate workflows for creating read count files, such as using snakemake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[Workflow One:](Tutorial_1.ipynb) A short introduction to downloading and mapping sequences to a transcriptome using Trimmomatic and Salmon. Here is a link to the YouTube video demonstrating the tutorial: <https://www.youtube.com/watch?v=NG1U7D4l31o&t=26s>.\n",
    "\n",
    "[Workflow One (Extended):](Tutorial_1B_Extended.ipynb) An extended version of workflow one. Once you have got your feet wet, you can retry workflow one with this extended version that covers the entire dataset, and includes elaboration such as using SRA tools for sequence downloading, and examples of running batches of fastq files through the pipeline. This workflow may take around an hour to run.\n",
    "\n",
    "[Workflow One (Using Snakemake):](Tutorial_2_Snakemake.ipynb) Using snakemake to run workflow one.\n",
    "\n",
    "[Workflow Two (DEG Analysis):](Tutorial_3_DEG_Analysis.ipynb) Using Deseq2 and R to conduct clustering and differential gene expression analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RNA-Seq workflow](images/RNA-Seq_Notebook_Homepage.png)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "r-cpu.4-1.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-1:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
